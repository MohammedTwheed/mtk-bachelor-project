[
  {
    "objectID": "index.html#beyond-trial-and-error-a-machine-learning-approach-to-optimal-centrifugal-pump-impeller-trimming",
    "href": "index.html#beyond-trial-and-error-a-machine-learning-approach-to-optimal-centrifugal-pump-impeller-trimming",
    "title": "Home",
    "section": "Beyond Trial and Error: A Machine Learning Approach to Optimal Centrifugal Pump Impeller Trimming",
    "text": "Beyond Trial and Error: A Machine Learning Approach to Optimal Centrifugal Pump Impeller Trimming\nThis paper proposes a novel method for optimizing pump impeller trimming using machine learning. Traditionally, this process relies on expertise and can be time-consuming. The proposed approach utilizes artificial neural networks (NNs) to predict impeller diameter and pump power based on desired operating conditions. A genetic algorithm (GA) then optimizes the NN for accurate predictions, leading to potentially faster and more efficient pump impeller trimming.\nKeywords: pump impeller trimming, machine learning, neural networks, genetic algorithm, neural network optimization\n\nLearn more »"
  },
  {
    "objectID": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html",
    "href": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html",
    "title": "Exploartion_17 : Tree-Based Genetic Programming for Polynomial Regression",
    "section": "",
    "text": "PDF\n\n\nMS Word"
  },
  {
    "objectID": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#download-this-doc-as-pdf-or-word",
    "href": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#download-this-doc-as-pdf-or-word",
    "title": "Exploartion_17 : Tree-Based Genetic Programming for Polynomial Regression",
    "section": "",
    "text": "PDF\n\n\nMS Word"
  },
  {
    "objectID": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#introduction",
    "href": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#introduction",
    "title": "Exploartion_17 : Tree-Based Genetic Programming for Polynomial Regression",
    "section": "Introduction",
    "text": "Introduction\nSymbolic regression, a technique used to identify mathematical expressions that best fit a given dataset, is a complex task often tackled using genetic programming (GP). Genetic programming mimics natural evolution to optimize candidate solutions, represented as mathematical expressions. This review explores the implementation of a genetic algorithm for symbolic regression using MATLAB, delving into the detailed structure of the genetic algorithm and the representation of mathematical expressions as tree structures. The following sections will elaborate on the genetic algorithm’s key components, the tree structure for representing mathematical expressions, and the nuances of the MATLAB implementation."
  },
  {
    "objectID": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#genetic-algorithm-implementation",
    "href": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#genetic-algorithm-implementation",
    "title": "Exploartion_17 : Tree-Based Genetic Programming for Polynomial Regression",
    "section": "Genetic Algorithm Implementation",
    "text": "Genetic Algorithm Implementation\nThe genetic algorithm (GA) for symbolic regression involves several critical steps: population initialization, selection, crossover, mutation, and fitness evaluation. Each of these steps is meticulously implemented in MATLAB to evolve mathematical expressions that best fit the provided data.\n\n1. Population Initialization\nPopulation initialization is achieved using the ramped half-and-half method, which ensures a diverse initial population. This method generates trees with varying depths and structures, promoting genetic diversity.\nfunction pop = initialPopulation(pop_size, max_depth, terminal_set, function_set)\n    pop = cell(1, pop_size);\n    for i = 1:pop_size\n        method = 'full';\n        if i &gt; (pop_size / 2)\n            method = 'grow';\n        end\n        pop{i} = growTree(max_depth, method, 0, terminal_set, function_set);\n    end\n    pop = pop(randperm(length(pop)));  % Randomize the population\nend\nThe growTree function generates individual trees using either the “full” method, creating fully populated trees to the maximum depth, or the “grow” method, generating trees with random depths.\n\n\n2. Selection\nTournament selection is employed to choose individuals for reproduction. This method ensures that individuals with better fitness are more likely to be selected, driving the population towards better solutions.\nfunction selected = tournamentSelection(pop, tour_size, x, y, rf, terminal_set)\n    selected_ind = randperm(length(pop), tour_size);\n    selected = cell(tour_size, 2);\n    for i = 1:tour_size\n        tree = pop{selected_ind(i)};\n        fitness = computeError(tree, x, y, rf, terminal_set);\n        selected{i, 1} = tree;\n        selected{i, 2} = fitness;\n    end\n    selected = sortrows(selected, 2);  % Sort based on fitness (ascending)\nend\nTournament selection enhances the likelihood of selecting fitter individuals while maintaining some level of genetic diversity, which is crucial for avoiding local optima.\n\n\n3. Crossover\nCrossover involves exchanging subtrees between pairs of parent trees to produce offspring with mixed characteristics. This operation introduces variability and combines the strengths of both parents.\nfunction [tree1, tree2] = crossover(tree1, tree2, c_rate)\n    if rand() &lt;= c_rate\n        swap_point1 = randi([0, countNodes(tree1) - 1]);\n        swap_point2 = randi([0, countNodes(tree2) - 1]);\n        subtree1 = getSubtree(tree1, swap_point1);\n        subtree2 = getSubtree(tree2, swap_point2);\n        tree1 = setSubtree(tree1, swap_point1, subtree2);\n        tree2 = setSubtree(tree2, swap_point2, subtree1);\n    end\nend\n\n\n4. Mutation\nMutation introduces random changes in the tree structure, which is essential for maintaining genetic diversity and exploring new solutions.\nfunction tree = mutate(tree, m_rate, max_depth, terminal_set, function_set)\n    if rand() &lt;= m_rate\n        mut_point = randi([0, countNodes(tree) - 1]);\n        subtree = growTree(max_depth, 'grow', 0, terminal_set, function_set);\n        tree = setSubtree(tree, mut_point, subtree);\n    end\nend\n\n\n5. Fitness Evaluation\nThe fitness of each tree is evaluated based on its ability to predict target values accurately. The fitness metric used is the root mean square error (RMSE), which quantifies the difference between the predicted and actual values.\nfunction error = computeError(tree, x, y, rf, terminal_set)\n    error_sum = 0;\n    n = length(x);\n    for i = 1:n\n        error_sum = error_sum + (computeTree(tree, x(i), y(i), terminal_set) - rf(i))^2;\n    end\n    error = sqrt(error_sum / n);\nend"
  },
  {
    "objectID": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#tree-structure-for-mathematical-expressions",
    "href": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#tree-structure-for-mathematical-expressions",
    "title": "Exploartion_17 : Tree-Based Genetic Programming for Polynomial Regression",
    "section": "Tree Structure for Mathematical Expressions",
    "text": "Tree Structure for Mathematical Expressions\nIn genetic programming, mathematical expressions are represented as tree structures, where nodes represent functions or terminals. Terminals can be variables (e.g., x, y) or constants (e.g., 1, 2), while functions are operators (e.g., +, -, *, /).\n\nTree Representation\nEach tree node is a structure with a value (operator or terminal) and pointers to its left and right child nodes.\nfunction node = createNode(value, left, right)\n    node = struct('value', value, 'left', left, 'right', right);\nend\n\n\nTree Generation\nTrees are generated using the growTree function, which recursively builds trees up to a specified maximum depth. The tree generation can follow the “full” method, creating fully populated trees, or the “grow” method, producing trees with variable depths.\nfunction tree = growTree(max_depth, method, depth, terminal_set, function_set)\n    if strcmp(method, 'full') && depth &lt; max_depth\n        left = growTree(max_depth, method, depth + 1, terminal_set, function_set);\n        right = growTree(max_depth, method, depth + 1, terminal_set, function_set);\n        value = drawValue('f', terminal_set, function_set);\n    elseif strcmp(method, 'grow') && depth &lt; max_depth\n        value = drawValue('tf', terminal_set, function_set);\n        if any(strcmp(value, terminal_set))\n            tree = createNode(value, [], []);\n            return;\n        end\n        left = growTree(max_depth, method, depth + 1, terminal_set, function_set);\n        right = growTree(max_depth, method, depth + 1, terminal_set, function_set);\n    else\n        value = drawValue('t', terminal_set, function_set);\n        left = [];\n        right = [];\n    end\n    tree = createNode(value, left, right);\nend\n\n\nTree Evaluation\nThe computeTree function recursively evaluates the tree by computing the value of each subtree and applying the respective operator.\nfunction result = computeTree(tree, x, y, terminal_set)\n    if any(strcmp(tree.value, terminal_set))\n        result = eval(tree.value);\n    else\n        left_val = computeTree(tree.left, x, y, terminal_set);\n        right_val = computeTree(tree.right, x, y, terminal_set);\n        if strcmp(tree.value, '/') && right_val == 0\n            result = 1; % Avoid division by zero\n        else\n            result = eval([num2str(left_val) tree.value num2str(right_val)]);\n        end\n    end\nend"
  },
  {
    "objectID": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#matlab-implementation-details",
    "href": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#matlab-implementation-details",
    "title": "Exploartion_17 : Tree-Based Genetic Programming for Polynomial Regression",
    "section": "MATLAB Implementation Details",
    "text": "MATLAB Implementation Details\nThe MATLAB code employs several programming techniques to ensure the efficient implementation of the genetic algorithm:\n\nModular Functions\nThe code is organized into modular functions, each responsible for a specific task, enhancing readability and maintainability.\n\n\nRandomization\nFunctions such as randperm and randi introduce randomness in the selection, crossover, and mutation processes, which is vital for maintaining genetic diversity.\n\n\nStructured Logging\nExecution progress and timing are logged using the logMessage function, providing valuable insights into the algorithm’s performance.\nfunction logMessage(message)\n    timestamp = datestr(now, 'yyyy-mm-dd HH:MM:SS');\n    fprintf('[%s] %s\\n', timestamp, message);\nend\n\n\nVisualization\n\n\n\n\n\n\nFigure 1: exanple plot with 200 generations\n\n\n\nThe plot visualizes the evolutionary process of symbolic regression using a genetic algorithm , highlighting the improvement in fitness (error reduction) and changes in solution complexity (tree depth) across generations. This approach aims to find mathematical expressions (symbolic models) that best fit the training data (A4_trainingSamples.txt). Each line provides critical insights into the algorithm’s performance and the nature of solutions generated over time.\nThe plotFigure function visualizes the evolution of fitness and tree depth over generations, aiding in the interpretation of the algorithm’s progress.\nfunction plotFigure(best_fit, avg_fit, worst_fit, tree_depth, gen)\n    generations = 10:10:gen;\n    figure;\n    yyaxis left\n    plot(generations, best_fit, 'r', generations, avg_fit, 'g', generations, worst_fit, 'b');\n    xlabel('Generation');\n    ylabel('Fitness');\n    legend('Best', 'Average', 'Worst');\n    \n    yyaxis right\n    plot(generations, tree_depth, 'c');\n    ylabel('Average Tree Depth');\n    legend('Tree Depth');\n    \n    title('Evolution of Fitness and Tree Depth');\nend\nPlot Explained:\nFitness Evolution (Left Y-axis):\nRed Line (Best Fitness): Represents the fitness (error) of the best individual in each generation. Green Line (Average Fitness): Shows the average fitness (error) of the population in each generation. Blue Line (Worst Fitness): Indicates the fitness (error) of the worst individual in each generation. These lines show how the fitness (error) values change over generations. The goal of the algorithm is typically to minimize this fitness value, as it represents the error in predicting the output (rf) based on the input (x, y).\nTree Depth Evolution (Right Y-axis):\nCyan Line (Average Tree Depth): Displays the average depth of the trees in the population for each generation. The depth of the trees is an indicator of their complexity. Genetic programming often evolves trees of varying depths, and monitoring the average tree depth helps in understanding the complexity of the solutions found over generations.\nX-axis (Generation):\nEach point on the x-axis represents a specific generation number (10:10:gen), where gen is the total number of generations specified in the code. Interpretation: Fitness Lines (Red, Green, Blue): Ideally, you want to see the red (best fitness) line decreasing over generations, indicating improvement in the best solution found. The green (average fitness) and blue (worst fitness) lines provide context on the overall performance of the population.\nTree Depth Line (Cyan): Monitoring the tree depth helps in understanding if the algorithm is converging towards simpler or more complex solutions. An increase in average tree depth might indicate overfitting or increasing complexity of solutions.\nSpecific Colors in the Plot: Green Line: Represents the average fitness (error) of the population. Blue Line: Represents the worst fitness (error) in the population. Cyan Line: Represents the average depth of trees in the population. These lines collectively show how the genetic algorithm progresses in terms of fitness (error minimization) and the complexity of the evolved solutions (average tree depth).\nThe plot helps in understanding how the fitness of the population improves over time and how the complexity of the solutions (tree depth) changes."
  },
  {
    "objectID": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#conclusion",
    "href": "data/writings/posts/2024-06-23-symbolic-regression-translation-to-matlab/index.html#conclusion",
    "title": "Exploartion_17 : Tree-Based Genetic Programming for Polynomial Regression",
    "section": "Conclusion",
    "text": "Conclusion\nThe MATLAB implementation of genetic programming\nfor symbolic regression is a robust approach that leverages the power of evolutionary algorithms to discover optimal mathematical expressions. Key features include structured functions, effective randomization, detailed logging, and clear visualization. This review highlights the importance of genetic diversity, modular programming, and the use of tree structures for representing mathematical expressions. These elements collectively enhance the effectiveness of symbolic regression using genetic algorithms.\n\nReferences\nthis part is still uderconstruction to be continued later"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "This project focuses on optimizing the performance of centrifugal pumps, which are essential in various industrial applications such as water supply systems and chemical processing. The optimization technique of interest is impeller trimming, which involves reducing the diameter of a pump impeller to better match the pump’s performance with the system requirements. This chapter explores the concept of impeller trimming, its significance, traditional methods, and the advantages of employing Artificial Intelligence (AI) for performance prediction.\n\n\n\nThe project aims to enhance energy efficiency and reduce operational costs by accurately predicting the effects of impeller trimming on pump performance. By leveraging AI techniques, particularly neural networks and genetic algorithms, the project seeks to provide precise predictions that can outperform traditional empirical methods.\n\n\n\n\nArtificial Neural Networks (ANNs): For predicting pump performance based on various input parameters.\nGenetic Algorithms (GAs): For optimizing the hyperparameters of the neural networks.\nMATLAB: As the primary platform for implementing the AI models and optimization algorithms.\n\n\n\n\n\n\n\nImpeller trimming is the process of mechanically reducing the diameter of the pump impeller. This adjustment directly influences the pump’s head and flow rate, thereby modifying its performance characteristics. Trimming is performed to ensure that the pump operates within the desired performance range, avoiding over-delivery or under-delivery of fluid.\n\n\n\n\n\nTrimming the impeller allows for the customization of pump performance to meet specific operational requirements. This customization is particularly necessary when: - The available pump sizes do not perfectly match the required system specifications. - System demands change over time, necessitating adjustments to maintain optimal efficiency. - Reducing the operational costs by minimizing energy wastage.\n\n\n\nCentrifugal pumps are often responsible for a significant portion of the energy consumption in industrial settings. Trimming the impeller to match the exact system requirements can greatly reduce the energy consumption of the pump. By operating more efficiently, the pump uses less power, leading to substantial energy savings. For every kilowatt (kW) saved by the pump, the reduction in power station output significantly decreases pollution.\n\n\n\nThe pumps available in the market may not always fit specific system requirements precisely. Typically, pumps are designed for a range of operations and may be larger or smaller than needed for a particular application. Impeller trimming allows for customizing the pump’s performance to meet these specific needs, ensuring that the pump operates at optimal efficiency.\n\n\n\n\n\nTrimming the impeller is not only beneficial for energy savings but also contributes to environmental sustainability. Reduced energy consumption leads to lower greenhouse gas emissions. For every kilowatt-hour (kWh) saved by the pump, the reduction in power station output significantly decreases pollution.\n\n\n\n\n\nTraditional methods for impeller trimming typically involve scaling laws and empirical correlations derived from extensive testing and experience. These methods include:\n\n\nConstant-area scaling assumes that the trimmed impeller maintains a constant area, ensuring proportional changes in flow and head. This method involves adjusting the impeller diameter while maintaining the proportional relationship between the flow rate and head.\n\\[\n\\text{constant-area scaling:} \\quad \\frac{Q'}{Q} = \\frac{D_2'}{D_2} \\frac{H'}{H} = \\left( \\frac{D_2'}{D_2} \\right)^2\n\\]\n\n\n\n\n\nArtificial Neural Networks (ANNs) offer a robust alternative to traditional methods by leveraging large datasets to predict pump performance accurately. Unlike empirical methods, ANNs can model complex, non-linear relationships between variables, providing more precise predictions.\n\n\n\nAccuracy: ANNs can learn from vast amounts of data, capturing intricate patterns and relationships that traditional methods might miss.\nEfficiency: Once trained, ANNs can quickly predict performance outcomes for different impeller diameters, saving time and resources.\nAdaptability: Neural networks can be updated with new data, continuously improving their predictive capabilities.\n\n\n\n\nThe architecture of the neural network plays a crucial role in its performance. Key components include: - Input Layer: Represents the features or variables used for prediction, such as flow rate and diameter. - Hidden Layers: Intermediate layers that process the inputs through weighted connections. The number of hidden layers and neurons per layer is optimized using hyperparameter tuning. - Output Layer: Provides the predicted performance metrics, such as head and power.\n\n\n\nThe training process involves adjusting the weights of the network to minimize the error between predicted and actual values. This is achieved through backpropagation and optimization algorithms.\n\n\n\nHyperparameters are settings that you adjust before training your neural network. These parameters influence the training process and the structure of the network. They are not learned from the data but are set by the user. In our code, we have chosen to optimize several hyperparameters, including:\n\nNumber of neurons in the hidden layers: This determines the capacity of the neural network to learn from the data. More neurons can capture more complex patterns but may also lead to overfitting if not managed properly.\nTraining method: This is specified by the choice of optimizer. In our code, we use the Levenberg-Marquardt (trainlm in MATLAB) optimizer for its efficiency in training feedforward networks.\nNumber of epochs: Epochs refer to the number of complete passes through the training dataset. Our code optimizes the number of epochs to ensure the model is well-trained without overfitting.\nActivation functions: These functions define the output of each neuron. We experiment with different activation functions like tansig and logsig to find the best fit for our model.\n\n\n\n\n\nGenetic algorithms (GAs) are a class of optimization techniques inspired by the process of natural selection. They are particularly useful for optimizing complex problems with large search spaces, such as neural network hyperparameter tuning.\n\n\n\nInitialization: A population of potential solutions (individuals) is generated. Each individual represents a set of hyperparameters.\nSelection: Individuals are selected based on their fitness, which is typically a function of how well they perform on a given task (e.g., predicting pump performance).\nCrossover: Pairs of individuals are combined to produce offspring. This process involves swapping parts of their hyperparameter sets to create new solutions.\nMutation: Some offspring undergo random changes to introduce diversity into the population.\nEvaluation: The fitness of the new generation is evaluated, and the best individuals are selected for the next iteration.\nTermination: The algorithm repeats the selection, crossover, mutation, and evaluation steps until a stopping criterion is met (e.g., a predefined number of generations or a satisfactory fitness level).\n\n\n\n\nIn our code, we use a genetic algorithm to optimize the hyperparameters of our neural network. The key steps involved are:\n\nDefine the Search Space: We specify the range for each hyperparameter, such as the number of neurons in hidden layers, the number of epochs, and the indices for the training and activation functions.\nSet Genetic Algorithm Options: We configure the genetic algorithm with options like population size, maximum number of generations, crossover fraction, and fitness limit.\nEvaluate Hyperparameters: A fitness function evaluates the performance of each set of hyperparameters. It trains the neural network and computes the mean squared error (MSE) across training, validation, and testing datasets.\nOptimize: The genetic algorithm iteratively searches for the optimal hyperparameters by generating new populations, evaluating their fitness, and selecting the best-performing sets.\n\nHere is an outline of the relevant code:\n% Define bounds for the genetic algorithm optimization\nlower_bounds = [2,  13,    13, 1, 1];\nupper_bounds = [2,  300,    300, 2, 1];\n\n% Genetic algorithm options\ngaOptions = optimoptions('ga', ...\n    'PopulationSize', 17, ...\n    'MaxGenerations', 13, ...\n    'CrossoverFraction', 0.8, ...\n    'ConstraintTolerance', 0.000991, ...\n    'FitnessLimit', 0.000991, ...\n    'EliteCount', 2, ...\n    'Display', 'iter', ...\n    'UseParallel', true);\n\n% Optimization using genetic algorithm\n[optimalHyperParams, finalMSE] = ga(@(hyperParams) evaluateHyperparameters(hyperParams, x, t, randomSeed), ...\n    length(lower_bounds), [], [], [], [], lower_bounds, upper_bounds, [], gaOptions);\nIn this section of the code, we set up the bounds for the hyperparameters and configure the genetic algorithm options. The evaluateHyperparameters function is called by the genetic algorithm to assess the performance of each set of hyperparameters, guiding the search towards the optimal solution.\nThe combination of neural networks and genetic algorithms provides a powerful approach for predicting the effects of impeller trimming on centrifugal pump performance. By leveraging AI techniques, we can achieve more accurate and efficient predictions, ultimately leading to better optimization of pump operations."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#introduction",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#introduction",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "This project focuses on optimizing the performance of centrifugal pumps, which are essential in various industrial applications such as water supply systems and chemical processing. The optimization technique of interest is impeller trimming, which involves reducing the diameter of a pump impeller to better match the pump’s performance with the system requirements. This chapter explores the concept of impeller trimming, its significance, traditional methods, and the advantages of employing Artificial Intelligence (AI) for performance prediction.\n\n\n\nThe project aims to enhance energy efficiency and reduce operational costs by accurately predicting the effects of impeller trimming on pump performance. By leveraging AI techniques, particularly neural networks and genetic algorithms, the project seeks to provide precise predictions that can outperform traditional empirical methods.\n\n\n\n\nArtificial Neural Networks (ANNs): For predicting pump performance based on various input parameters.\nGenetic Algorithms (GAs): For optimizing the hyperparameters of the neural networks.\nMATLAB: As the primary platform for implementing the AI models and optimization algorithms."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#the-concept-of-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#the-concept-of-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Impeller trimming is the process of mechanically reducing the diameter of the pump impeller. This adjustment directly influences the pump’s head and flow rate, thereby modifying its performance characteristics. Trimming is performed to ensure that the pump operates within the desired performance range, avoiding over-delivery or under-delivery of fluid.\n\n\n\n\n\nTrimming the impeller allows for the customization of pump performance to meet specific operational requirements. This customization is particularly necessary when: - The available pump sizes do not perfectly match the required system specifications. - System demands change over time, necessitating adjustments to maintain optimal efficiency. - Reducing the operational costs by minimizing energy wastage.\n\n\n\nCentrifugal pumps are often responsible for a significant portion of the energy consumption in industrial settings. Trimming the impeller to match the exact system requirements can greatly reduce the energy consumption of the pump. By operating more efficiently, the pump uses less power, leading to substantial energy savings. For every kilowatt (kW) saved by the pump, the reduction in power station output significantly decreases pollution.\n\n\n\nThe pumps available in the market may not always fit specific system requirements precisely. Typically, pumps are designed for a range of operations and may be larger or smaller than needed for a particular application. Impeller trimming allows for customizing the pump’s performance to meet these specific needs, ensuring that the pump operates at optimal efficiency."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#energy-savings-and-environmental-impact",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#energy-savings-and-environmental-impact",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Trimming the impeller is not only beneficial for energy savings but also contributes to environmental sustainability. Reduced energy consumption leads to lower greenhouse gas emissions. For every kilowatt-hour (kWh) saved by the pump, the reduction in power station output significantly decreases pollution."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#traditional-methods-of-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#traditional-methods-of-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Traditional methods for impeller trimming typically involve scaling laws and empirical correlations derived from extensive testing and experience. These methods include:\n\n\nConstant-area scaling assumes that the trimmed impeller maintains a constant area, ensuring proportional changes in flow and head. This method involves adjusting the impeller diameter while maintaining the proportional relationship between the flow rate and head.\n\\[\n\\text{constant-area scaling:} \\quad \\frac{Q'}{Q} = \\frac{D_2'}{D_2} \\frac{H'}{H} = \\left( \\frac{D_2'}{D_2} \\right)^2\n\\]"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#artificial-neural-networks-for-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#artificial-neural-networks-for-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Artificial Neural Networks (ANNs) offer a robust alternative to traditional methods by leveraging large datasets to predict pump performance accurately. Unlike empirical methods, ANNs can model complex, non-linear relationships between variables, providing more precise predictions.\n\n\n\nAccuracy: ANNs can learn from vast amounts of data, capturing intricate patterns and relationships that traditional methods might miss.\nEfficiency: Once trained, ANNs can quickly predict performance outcomes for different impeller diameters, saving time and resources.\nAdaptability: Neural networks can be updated with new data, continuously improving their predictive capabilities.\n\n\n\n\nThe architecture of the neural network plays a crucial role in its performance. Key components include: - Input Layer: Represents the features or variables used for prediction, such as flow rate and diameter. - Hidden Layers: Intermediate layers that process the inputs through weighted connections. The number of hidden layers and neurons per layer is optimized using hyperparameter tuning. - Output Layer: Provides the predicted performance metrics, such as head and power.\n\n\n\nThe training process involves adjusting the weights of the network to minimize the error between predicted and actual values. This is achieved through backpropagation and optimization algorithms.\n\n\n\nHyperparameters are settings that you adjust before training your neural network. These parameters influence the training process and the structure of the network. They are not learned from the data but are set by the user. In our code, we have chosen to optimize several hyperparameters, including:\n\nNumber of neurons in the hidden layers: This determines the capacity of the neural network to learn from the data. More neurons can capture more complex patterns but may also lead to overfitting if not managed properly.\nTraining method: This is specified by the choice of optimizer. In our code, we use the Levenberg-Marquardt (trainlm in MATLAB) optimizer for its efficiency in training feedforward networks.\nNumber of epochs: Epochs refer to the number of complete passes through the training dataset. Our code optimizes the number of epochs to ensure the model is well-trained without overfitting.\nActivation functions: These functions define the output of each neuron. We experiment with different activation functions like tansig and logsig to find the best fit for our model."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#genetic-algorithm-for-hyperparameter-optimization",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_04.html#genetic-algorithm-for-hyperparameter-optimization",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Genetic algorithms (GAs) are a class of optimization techniques inspired by the process of natural selection. They are particularly useful for optimizing complex problems with large search spaces, such as neural network hyperparameter tuning.\n\n\n\nInitialization: A population of potential solutions (individuals) is generated. Each individual represents a set of hyperparameters.\nSelection: Individuals are selected based on their fitness, which is typically a function of how well they perform on a given task (e.g., predicting pump performance).\nCrossover: Pairs of individuals are combined to produce offspring. This process involves swapping parts of their hyperparameter sets to create new solutions.\nMutation: Some offspring undergo random changes to introduce diversity into the population.\nEvaluation: The fitness of the new generation is evaluated, and the best individuals are selected for the next iteration.\nTermination: The algorithm repeats the selection, crossover, mutation, and evaluation steps until a stopping criterion is met (e.g., a predefined number of generations or a satisfactory fitness level).\n\n\n\n\nIn our code, we use a genetic algorithm to optimize the hyperparameters of our neural network. The key steps involved are:\n\nDefine the Search Space: We specify the range for each hyperparameter, such as the number of neurons in hidden layers, the number of epochs, and the indices for the training and activation functions.\nSet Genetic Algorithm Options: We configure the genetic algorithm with options like population size, maximum number of generations, crossover fraction, and fitness limit.\nEvaluate Hyperparameters: A fitness function evaluates the performance of each set of hyperparameters. It trains the neural network and computes the mean squared error (MSE) across training, validation, and testing datasets.\nOptimize: The genetic algorithm iteratively searches for the optimal hyperparameters by generating new populations, evaluating their fitness, and selecting the best-performing sets.\n\nHere is an outline of the relevant code:\n% Define bounds for the genetic algorithm optimization\nlower_bounds = [2,  13,    13, 1, 1];\nupper_bounds = [2,  300,    300, 2, 1];\n\n% Genetic algorithm options\ngaOptions = optimoptions('ga', ...\n    'PopulationSize', 17, ...\n    'MaxGenerations', 13, ...\n    'CrossoverFraction', 0.8, ...\n    'ConstraintTolerance', 0.000991, ...\n    'FitnessLimit', 0.000991, ...\n    'EliteCount', 2, ...\n    'Display', 'iter', ...\n    'UseParallel', true);\n\n% Optimization using genetic algorithm\n[optimalHyperParams, finalMSE] = ga(@(hyperParams) evaluateHyperparameters(hyperParams, x, t, randomSeed), ...\n    length(lower_bounds), [], [], [], [], lower_bounds, upper_bounds, [], gaOptions);\nIn this section of the code, we set up the bounds for the hyperparameters and configure the genetic algorithm options. The evaluateHyperparameters function is called by the genetic algorithm to assess the performance of each set of hyperparameters, guiding the search towards the optimal solution.\nThe combination of neural networks and genetic algorithms provides a powerful approach for predicting the effects of impeller trimming on centrifugal pump performance. By leveraging AI techniques, we can achieve more accurate and efficient predictions, ultimately leading to better optimization of pump operations."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#introduction",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#introduction",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Introduction",
    "text": "Introduction\nCentrifugal pumps are pivotal components in various industrial applications, from water supply systems to chemical processing. Optimizing their performance is crucial for enhancing energy efficiency and reducing operational costs. One key optimization technique is impeller trimming, which involves reducing the diameter of a pump impeller to align the pump’s performance more closely with the system requirements. This chapter explores the concept of impeller trimming, its significance, traditional methods, and the advantages of employing Artificial Intelligence (AI) for performance prediction."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#the-concept-of-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#the-concept-of-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "The Concept of Impeller Trimming",
    "text": "The Concept of Impeller Trimming\n\nWhat is Trimming?\nImpeller trimming is the process of mechanically reducing the diameter of the pump impeller. This adjustment directly influences the pump’s head and flow rate, thereby modifying its performance characteristics. Trimming is performed to ensure that the pump operates within the desired performance range, avoiding over-delivery or under-delivery of fluid.\n\n\nWhy Trimming?\n\n\nThe Need for Trimming\nTrimming the impeller allows for the customization of pump performance to meet specific operational requirements. This customization is particularly necessary when: - The available pump sizes do not perfectly match the required system specifications. - System demands change over time, necessitating adjustments to maintain optimal efficiency. - Reducing the operational costs by minimizing energy wastage.\n\nEnergy Consumption\nCentrifugal pumps are often responsible for a significant portion of the energy consumption in industrial settings. Trimming the impeller to match the exact system requirements can greatly reduce the energy consumption of the pump. By operating more efficiently, the pump uses less power, leading to substantial energy savings where for each 1 kw in pump delivery corresponds to 6 kwhr in power station.\n\n\nMarket Availability\nThe pumps available in the market may not always fit specific system requirements precisely. Typically, pumps are designed for a range of operations and may be larger or smaller than needed for a particular application. Impeller trimming allows for customizing the pump’s performance to meet these specific needs, ensuring that the pump operates at optimal efficiency."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#energy-savings-and-environmental-impact",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#energy-savings-and-environmental-impact",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Energy Savings and Environmental Impact",
    "text": "Energy Savings and Environmental Impact\nTrimming the impeller is not only beneficial for energy savings but also contributes to environmental sustainability. Reduced energy consumption leads to lower greenhouse gas emissions. For every kilowatt-hour (kWh) saved by the pump, the reduction in power station output significantly decreases pollution. This correlation is particularly stark, with each kilowatt saved at the pump corresponding to approximately six kilowatts saved at the power station."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#traditional-methods-of-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#traditional-methods-of-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Traditional Methods of Impeller Trimming",
    "text": "Traditional Methods of Impeller Trimming\n\nScaling Methods\nTraditional methods for impeller trimming typically involve scaling laws and empirical correlations derived from extensive testing and experience. These methods include:\n\nConstant-Area Scaling\nConstant-area scaling assumes that the trimmed impeller maintains a constant area, ensuring proportional changes in flow and head. This method involves adjusting the impeller diameter while maintaining the proportional relationship between the flow rate and head.\n\\[\n\\text{constant-area scaling:} \\quad \\frac{Q'}{Q} = \\frac{D_2'}{D_2} \\frac{H'}{H} = \\left( \\frac{D_2'}{D_2} \\right)^2\n\\]"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#artificial-neural-networks-for-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#artificial-neural-networks-for-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Artificial Neural Networks for Impeller Trimming",
    "text": "Artificial Neural Networks for Impeller Trimming\nArtificial Neural Networks (ANNs) offer a robust alternative to traditional methods by leveraging large datasets to predict pump performance accurately. Unlike empirical methods, ANNs can model complex, non-linear relationships between variables, providing more precise predictions.\n\nAdvantages of Neural Networks\n\nAccuracy: ANNs can learn from vast amounts of data, capturing intricate patterns and relationships that traditional methods might miss.\nEfficiency: Once trained, ANNs can quickly predict performance outcomes for different impeller diameters, saving time and resources.\nAdaptability: Neural networks can be updated with new data, continuously improving their predictive capabilities.\n\n\n\nNeural Network Architecture\nThe architecture of the neural network plays a crucial role in its performance. Key components include: - Input Layer: Represents the features or variables used for prediction, such as flow rate and diameter. - Hidden Layers: Intermediate layers that process the inputs through weighted connections. The number of hidden layers and neurons per layer is optimized using hyperparameter tuning. - Output Layer: Provides the predicted performance metrics, such as head and power.\n\n\nTraining the Neural Network\nThe training process involves adjusting the weights of the network to minimize the error between predicted and actual values. This is achieved through backpropagation and optimization algorithms.\n\n\nHyperparameters and Unlearnable Parameters\nHyperparameters are settings that you adjust before training your neural network. These parameters influence the training process and the structure of the network. They are not learned from the data but are set by the user. In our code, we have chosen to optimize several hyperparameters, including:\n\nNumber of neurons in the hidden layers: This determines the capacity of the neural network to learn from the data. More neurons can capture more complex patterns but may also lead to overfitting if not managed properly.\nTraining method: This is specified by the choice of optimizer. In our code, we use the Levenberg-Marquardt (trainlm in MATLAB) optimizer for its efficiency in training feedforward networks.\nNumber of epochs: Epochs refer to the number of complete passes through the training dataset. Our code optimizes the number of epochs to ensure the model is well-trained without overfitting.\nActivation functions: These functions define the output of each neuron. We experiment with different activation functions like tansig and logsig to find the best fit for our model."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#genetic-algorithm-for-hyperparameter-optimization",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#genetic-algorithm-for-hyperparameter-optimization",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Genetic Algorithm for Hyperparameter Optimization",
    "text": "Genetic Algorithm for Hyperparameter Optimization\nGenetic algorithms (GAs) are a class of optimization techniques inspired by the process of natural selection. They are particularly useful for optimizing complex problems with large search spaces, such as neural network hyperparameter tuning.\n\nHow Genetic Algorithms Work\n\nInitialization: A population of potential solutions (individuals) is generated. Each individual represents a set of hyperparameters.\nSelection: Individuals are selected based on their fitness, which is typically a function of how well they perform on a given task (e.g., predicting pump performance).\nCrossover: Pairs of individuals are combined to produce offspring. This process involves swapping parts of their hyperparameter sets to create new solutions.\nMutation: Some offspring undergo random changes to introduce diversity into the population.\nEvaluation: The fitness of the new generation is evaluated, and the best individuals are selected for the next iteration.\nTermination: The algorithm repeats the selection, crossover, mutation, and evaluation steps until a stopping criterion is met (e.g., a predefined number of generations or a satisfactory fitness level).\n\n\n\nUsing Genetic Algorithms in Our Code\nIn our code, we use a genetic algorithm to optimize the hyperparameters of our neural network. The key steps involved are:\n\nDefine the Search Space: We specify the range for each hyperparameter, such as the number of neurons in hidden layers, the number of epochs, and the indices for the training and activation functions.\nSet Genetic Algorithm Options: We configure the genetic algorithm with options like population size, maximum number of generations, crossover fraction, and fitness limit.\nEvaluate Hyperparameters: A fitness function evaluates the performance of each set of hyperparameters. It trains the neural network and computes the mean squared error (MSE) across training, validation, and testing datasets.\nOptimize: The genetic algorithm iteratively searches for the optimal hyperparameters by generating new populations, evaluating their fitness, and selecting the best-performing sets.\n\nHere is an outline of the relevant code:\n% Define bounds for the genetic algorithm optimization\nlower_bounds = [2,  13,    13, 1, 1];\nupper_bounds = [2,  300,    300, 2, 1];\n\n% Genetic algorithm options\ngaOptions = optimoptions('ga', ...\n    'PopulationSize', 17, ...\n    'MaxGenerations', 13, ...\n    'CrossoverFraction', 0.8, ...\n    'ConstraintTolerance', 0.000991, ...\n    'FitnessLimit', 0.000991, ...\n    'EliteCount', 2, ...\n    'Display', 'iter', ...\n    'UseParallel', true);\n\n% Optimization using genetic algorithm\n[optimalHyperParams, finalMSE] = ga(@(hyperParams) evaluateHyperparameters(hyperParams, x, t, randomSeed), ...\n    length(lower_bounds), [], [], [], [], lower_bounds, upper_bounds, [], gaOptions);\nIn this section of the code, we set up the bounds for the hyperparameters and configure the genetic algorithm options. The evaluateHyperparameters function is called by the genetic algorithm to assess the performance of each set of hyperparameters, guiding the search towards the optimal solution.\nThe combination of neural networks and genetic algorithms provides a powerful approach for predicting pump performance with high accuracy and efficiency, leveraging advanced optimization techniques to fine-tune the model. ## Genetic Algorithm for Hyperparameter Optimization\nA genetic algorithm (GA) is used to optimize the hyperparameters of the neural network. GA is a search heuristic that mimics the process of natural selection, making it effective for exploring large and complex search spaces.\n\n\nKey Steps in Genetic Algorithm\n\nInitialization: Creating an initial population of potential solutions with random hyperparameters.\nSelection: Evaluating the fitness of each individual in the population based on the mean squared error (MSE) of the neural network’s predictions.\nCrossover: Combining pairs of individuals to produce offspring with mixed characteristics, promoting the inheritance of good traits.\nMutation: Introducing random changes to some individuals to maintain genetic diversity and explore new solutions.\nEvaluation: Assessing the performance of the new population and iterating through the selection, crossover, and mutation steps until convergence or a predefined number of generations is reached."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#implementation-in-matlab",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#implementation-in-matlab",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Implementation in MATLAB",
    "text": "Implementation in MATLAB\nThe implementation of AI for impeller trimming was carried out using MATLAB. The scripts main_04.m and QHforDiameters.m are critical components of this implementation, leveraging optimized neural network architectures to predict pump performance based on different impeller diameters.\n\nScript: main_04.m\nThe main_04.m script incorporates the following key steps:\n\nData Loading: Loading datasets containing flow rate, head, diameter, and power metrics.\nNetwork Training: Training neural networks with optimized architectures to predict head and power based on flow rate and diameter.\nPerformance Evaluation: Evaluating the trained networks on various performance metrics to ensure accuracy and reliability.\nVisualization: Generating 3D plots to visualize the relationship between flow rate, head, diameter, and power, showcasing the neural network predictions versus actual data.\n\n\nKey Functions and Their Roles\n\ntrain_nn: This function trains the neural network using the provided data, returning the trained model and performance metrics.\ntrim_diameters: This function determines the optimal trimmed diameter based on the provided pump data and performance criteria.\nprocessDataAndVisualize: This function processes the data and generates visualizations to compare neural network predictions with actual data points.\n\n\n\nSample Code Snippet from main_04.m\nThe following MATLAB code snippet from main_04.m demonstrates how to load data, train neural networks, and visualize the results:\nclear; clc; clf; close all;\n\n% Load data\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\n% Extract data\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD = [filtered_QHD_table.Diameter_mm]';\nQD = [filtered_QDP_table.FlowRate_m3h, filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\n% Train on full dataset\n[trainedNetQHD, ~, ~, ~, ~] = train_nn([2, 16], 191, 'trainlm', QH, D, 4837);\n[trainedNetQDP, ~, ~, ~, ~] = train_nn([2, 7, 29, 17], 191, 'trainlm', QD, P, 4837);\n\n% Visualization\nprocessDataAndVisualize(QH', D', QD', P', trainedNetQHD, trainedNetQDP, 'figures');\n\n\n\nScript: QHforDiameters.m\nThe QHforDiameters.m script focuses on optimizing neural network hyperparameters for better performance prediction. It uses a genetic algorithm to find the optimal neural network architecture, ensuring accurate predictions for different impeller diameters.\n\nKey Steps in QHforDiameters.m\n\nInitialization: Loading data and initializing variables.\nHyperparameter Optimization: Using a genetic algorithm to find the optimal neural network architecture.\nPerformance Evaluation: Assessing the neural network’s performance on the training and test datasets.\nVisualization: Plotting the predicted performance curves for different impeller diameters.\n\n\n\nSample Code Snippet from QHforDiameters.m\nThe following MATLAB code snippet from QHforDiameters.m illustrates the process of optimizing neural network hyperparameters and visualizing the results:\nclear; clc; clf;\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD  = [filtered_QHD_table.Diameter_mm]';\n\nQH_beps=[deleted_QHD_table.FlowRate_m3h,deleted_QHD_table.Head_m]';\nD_beps\n\n=[deleted_QHD_table.Diameter_mm]';\n\nQD = [filtered_QDP_table.FlowRate_m3h,filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\nQD_beps=[deleted_QDP_table.FlowRate_m3h,deleted_QDP_table.Diameter_mm]';\nP_beps=[deleted_QDP_table.Power_kW]';\n\n% User-specified random seed (optional)\nuserSeed = 4826;\n\n% Define a threshold for MSE to exit the loop early\nmseThreshold = 0.000199;\n\n% Initialize result matrix\nresult = [];\n\n% Find all distinct diameters in D\ndistinctDiameters = unique(D);\n\n% Weights for combining MSEs\nweightDiameter = 0.5;\nweightBeps = 0.5;\n\nfor dIdx = 1:length(distinctDiameters)\n    % Current diameter to remove\n    diameterToRemove = distinctDiameters(dIdx);\n    \n    % Remove the current diameter from QH and D\n    idxToKeep = D ~= diameterToRemove;\n    QH_filtered = QH(:, idxToKeep);\n    D_filtered = D(idxToKeep);\n    \n    % Calculate the number of epochs based on dataset size\n    maxEpochs = 1000 + floor(size(QH_filtered, 2) / 10);\n    \n    % Determine the number of hidden layers and neurons to search\n    hiddenLayers = [1:10];\n    neuronsPerLayer = [1:30];\n    \n    % Initialize the best MSE and corresponding architecture\n    bestMSE = Inf;\n    bestArch = [];\n    \n    % Random seed for reproducibility"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#results",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#results",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Results",
    "text": "Results\n\nQHD results table\n\nimport pandas as pd\n\n# Load the QHD results table\nqhd_results = pd.read_csv('QHD_results.csv')\n# Rename columns to ensure headers are displayed correctly\nqhd_results.columns = ['DiameterRemoved', 'AvgMSE', 'TrainPerformance', 'ValPerformance', 'TestPerformance', 'MSEDeletedDiameter', 'MSEBEPs']\nqhd_results\n\n\n\n\n\n\n\n\nDiameterRemoved\nAvgMSE\nTrainPerformance\nValPerformance\nTestPerformance\nMSEDeletedDiameter\nMSEBEPs\n\n\n\n\n0\n230\n0.025035\n0.006973\n0.013087\n0.063566\n13.109880\n0.887325\n\n\n1\n240\n0.002054\n0.001905\n0.002182\n0.002146\n0.174083\n0.033176\n\n\n2\n250\n0.003343\n0.002433\n0.004716\n0.003316\n0.626366\n0.015352\n\n\n3\n260\n0.002077\n0.001944\n0.001985\n0.002364\n23.101650\n0.330787\n\n\n\n\n\n\n\n\n\nQDP results tabel\n\n# Load the QDP results table\nqdp_results = pd.read_csv('QDP_results.csv')\nqdp_results.columns = ['DiameterRemoved', 'AvgMSE', 'TrainPerformance', 'ValPerformance', 'TestPerformance', 'MSEDeletedDiameter', 'MSEBEPs']\nqdp_results\n\n\n\n\n\n\n\n\nDiameterRemoved\nAvgMSE\nTrainPerformance\nValPerformance\nTestPerformance\nMSEDeletedDiameter\nMSEBEPs\n\n\n\n\n0\n230\n1.061458\n1.074642\n1.005925\n1.097531\n1.459545\n0.504712\n\n\n1\n240\n0.856944\n0.717666\n0.856781\n1.062996\n2.272058\n0.855605\n\n\n2\n250\n0.001608\n0.001304\n0.001949\n0.001718\n11.410656\n0.001787\n\n\n3\n260\n0.001312\n0.001193\n0.001446\n0.001355\n3.709925\n0.001861\n\n\n\n\n\n\n\n\n\nQDH results tabel\n\n# Load the QDH results table\nqdh_results = pd.read_csv('QDH_results.csv')\nqdh_results.columns = ['DiameterRemoved', 'AvgMSE', 'TrainPerformance', 'ValPerformance', 'TestPerformance', 'MSEDeletedDiameter', 'MSEBEPs']\nqdh_results\n\n\n\n\n\n\n\n\nDiameterRemoved\nAvgMSE\nTrainPerformance\nValPerformance\nTestPerformance\nMSEDeletedDiameter\nMSEBEPs\n\n\n\n\n0\n230\n0.003924\n0.002607\n0.002910\n0.006876\n0.030449\n0.001832\n\n\n1\n240\n2.324643\n2.171064\n2.720251\n2.155551\n22.142540\n4.378357\n\n\n2\n250\n0.002601\n0.001929\n0.003371\n0.002826\n781.213228\n201.866566\n\n\n3\n260\n0.002949\n0.002372\n0.004189\n0.002559\n5.875235\n0.017837\n\n\n\n\n\n\n\n\n\nerrors and reductions\nhere we compare the best neural network we have with the traditional constant area scaling methode form [weme paper need citation] where\n% Loop through each column in QH_beps\nfor i = 1:5\n    d_real = D_beps(1, i); % Extracting d_real from D_beps\n\n    % Calculate d using constant_area_scaling\n    d_trimmed_cas_260 = constant_area_scaling(QH_beps(1, i), QH_beps(2, i), pump_data(5).Q, pump_data(5).H, pump_data(5).Diameter, 4);\n    percent_errors_cas_260(i) = abs((d_trimmed_cas_260 - d_real) / d_real) * 100;\n\n    % Calculate d using trim_diameters\n    d_trimmed_cas_nearest = trim_diameters(QH_beps(:, i), 'filtered_QHD_table.mat');\n    percent_errors_cas_nearest(i) = abs((d_trimmed_cas_nearest - d_real) / d_real) * 100;\n\n    % Calculate d using trainedNetQHD\n    d_trimmed_nn = bestNetQHD.net(QH_beps(:, i));\n    percent_errors_nn(i) = abs((d_trimmed_nn - d_real) / d_real) * 100;\n\n    % Calculate percent reduction in diameter\n    percent_reductions(i) = abs((d_real - d_trimmed_nn) / d_real) * 100;\nend\nas we see here we do so in two different variants where in percent_errors_cas_260 we feed to constant_area_scaling the last diameter the $ 260:mm $ diameter as the base diameter and for all the test points which are the best effecincy points they will trimm form it and this gives greater error as you see below.\nwhile trim_diameters the function will find the nearst curve from the given 5 curves to trim againist it and this will reduce the error so much but it still higher that the nn by order of magnitude.\n\nerros_reductions = pd.read_csv('errors_and_reductions.csv')\nerros_reductions .columns = ['Index', 'Percent_Error_CAS_260', 'Percent_Error_CAS_Nearest', 'Percent_Error_NN', 'Percent_Reduction']\nerros_reductions \n\n\n\n\n\n\n\n\nIndex\nPercent_Error_CAS_260\nPercent_Error_CAS_Nearest\nPercent_Error_NN\nPercent_Reduction\n\n\n\n\n0\n1\n241.145202\n3.261635\n2.541009\n2.541009\n\n\n1\n2\n241.798697\n3.076349\n3.588867\n3.588867\n\n\n2\n3\n238.978142\n8.063994\n3.085461\n3.085461\n\n\n3\n4\n228.293618\n1.351752\n2.207965\n2.207965\n\n\n4\n5\n245.536126\n3.828971\n2.299324\n2.299324\n\n\n\n\n\n\n\n\n\nfinal stats\n\nfstats = pd.read_csv('final_statistics.csv')\nfstats.columns = ['MAE_Trim_Diameters', 'MAE_TrainedNetQHD', 'Count_Better_TrainedNetQHD', 'Count_Better_Trim_Diameters']\nfstats\n\n\n\n\n\n\n\n\nMAE_Trim_Diameters\nMAE_TrainedNetQHD\nCount_Better_TrainedNetQHD\nCount_Better_Trim_Diameters\n\n\n\n\n0\n3.91654\n2.744525\n3\n2"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#conclusion",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#conclusion",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Conclusion",
    "text": "Conclusion\nThe use of Artificial Intelligence, particularly neural networks and genetic algorithms, provides a powerful tool for predicting the effects of impeller trimming on centrifugal pump performance. This approach offers significant advantages in terms of accuracy, efficiency, and adaptability, making it a superior alternative to traditional methods. By optimizing pump performance, we can achieve substantial energy savings and reduce environmental impact, contributing to a more sustainable industrial practice."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#code-breakdown",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index.html#code-breakdown",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Code Breakdown",
    "text": "Code Breakdown\n\nInitial Setup\nThe script begins by clearing the workspace and loading several data files:\nclear; clc; clf;\nload('filtered_QHD_table.mat')\nload('filtered_QDP_table.mat')\nload('deleted_QHD_table.mat')\nload('deleted_QDP_table.mat')\n\nfiltered_QHD_table.mat and filtered_QDP_table.mat: Contain the filtered data for flow rate (Q), head (H), and power (P) against diameters (D).\ndeleted_QHD_table.mat and deleted_QDP_table.mat: Contain the data points excluded from the filtered tables.\n\n\n\nData Preparation\nThe loaded data is then organized into matrices for further processing:\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD  = [filtered_QHD_table.Diameter_mm]';\n\nQH_beps = [deleted_QHD_table.FlowRate_m3h, deleted_QHD_table.Head_m]';\nD_beps = [deleted_QHD_table.Diameter_mm]';\n\nQD = [filtered_QDP_table.FlowRate_m3h, filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\nQD_beps = [deleted_QDP_table.FlowRate_m3h, deleted_QDP_table.Diameter_mm]';\nP_beps = [deleted_QDP_table.Power_kW]';\nHere, we arrange the data into variables for flow rate and head (QH), diameters (D), and power (P).\n\n\nHyperparameter Optimization Setup\nWe define several key parameters for the optimization process:\nuserSeed = 4826;\nmseThreshold = 0.000199;\nresult = [];\ndistinctDiameters = unique(D);\n\nweightDiameter = 0.5;\nweightBeps = 0.5;\n\nuserSeed: A seed for random number generation to ensure reproducibility.\nmseThreshold: The mean squared error threshold for early stopping.\ndistinctDiameters: A unique set of diameters for which we’ll optimize our neural network.\n\n\n\nOptimization Loop\nThe core of the script involves iterating over each distinct diameter, removing it from the dataset, and training a neural network to predict the head (H) given the flow rate (Q) and the diameter (D):\nfor dIdx = 1:length(distinctDiameters)\n    diameterToRemove = distinctDiameters(dIdx);\n    indicesToRemove = find(D == diameterToRemove);\n    removedQH = QH(:, indicesToRemove);\n    removedD = D(indicesToRemove);\n    QH_temp = QH;\n    D_temp = D;\n    QH_temp(:, indicesToRemove) = [];\n    D_temp(:, indicesToRemove) = [];\n    \n    Qa = QH_temp(1,:);\n    Ha = QH_temp(2,:);\n    Q = QH_temp(1,:);\n    H = QH_temp(2,:);\n\n    lower_bounds = [2, 13, 13, 1, 1];\n    upper_bounds = [2, 300, 300, 2, 1];\n    prevCombinedMSE = inf;\n\n    for i = 1:20\n        [optimalHyperParamsH, finalMSEH, randomSeedH, bestTrainedNetH, error] = ...\n            optimizeNNForTrimmingPumpImpeller([QH_temp(1,:); D_temp], QH_temp(2,:), userSeed+i, lower_bounds, upper_bounds);\n\n        result(i, :) = [i, optimalHyperParamsH, finalMSEH, randomSeedH, error(1), error(2), error(3)];\n        predictedH = bestTrainedNetH([removedQH(1, :); removedD])';\n        mseDiameter = mean((removedQH(2, :)' - predictedH).^2 / sum(removedQH(2, :)));\n\n        predictedH_beps = bestTrainedNetH([QH_beps(1,:); D_beps])';\n        mseQH_beps = mean((QH_beps(2,:)' - predictedH_beps).^2 / sum(QH_beps(2,:)));\n\n        fprintf('Diameter %d, Iteration %d, MSE_Dia: %.6f,  MSE_beps: %.6f \\n', diameterToRemove, i, mseDiameter, mseQH_beps);\n\n        combinedMSE = weightDiameter * mseDiameter + weightBeps * mseQH_beps;\n        deltaMSE = prevCombinedMSE - combinedMSE;\n        \n        if deltaMSE &gt; 0.01\n            adjustment = [0, 5, 15, 0, 0];\n        elseif deltaMSE &gt; 0.001\n            adjustment = [0, 2, 10, 0, 0];\n        else\n            adjustment = [0, 1, 5, 0, 0];\n        end\n        \n        lower_bounds = max(lower_bounds, [2, optimalHyperParamsH(2), optimalHyperParamsH(3), 1, 1] - adjustment);\n        upper_bounds = min(upper_bounds, [2, optimalHyperParamsH(2), optimalHyperParamsH(3), 2, 1] + adjustment);\n        prevCombinedMSE = combinedMSE;\n\n        if (mseDiameter &lt; mseThreshold) && (error(3) &lt; 0.0199) && (mseQH_beps &lt; mseThreshold)\n            fprintf('MSE for diameter %d is below the threshold. Exiting loop.\\n', diameterToRemove);\n            break;\n        end\n    end\nend\n\n\nPlotting Results\nThe script generates plots to visualize the performance of the neural network:\nfor diameterIndex = 1:length(desiredDiameters)\n    desiredDiameter = desiredDiameters(diameterIndex);\n    Dt = repmat(desiredDiameter, length(Qt), 1);\n    filteredQH = bestTrainedNetH([Qt; Dt'])';\n\n    legendLabel = strcat('Diameter: ', num2str(desiredDiameter), 'mm');\n    plot(Qt, filteredQH, 'DisplayName', legendLabel);\n    text(Qt(end), filteredQH(end), sprintf('%dmm', desiredDiameter), 'FontSize', 8, 'Color', 'black', 'BackgroundColor', 'white');\nend\n\nscatter(Qa', Ha', 'b', 'filled', 'DisplayName', 'Reference Points');\nxlabel('Q (m^3/h)');\nylabel('H (m)');\ntitle(['(Q, H) slices with Diameters, Removed Diameter: ' num2str(diameterToRemove) 'mm']);\nlegend;\nhold off;\n\n\nSaving Results\nThe results and trained networks are saved for further analysis:\nfilename = sprintf('../loop_05/01/nn_diameter-%d_iteration_%d_%d-%d-%d-%d-%d_mseDia-%d_test-%d.png', diameterToRemove, i, ...\n    optimalHyperParamsH(1), optimalHyperParamsH(2), optimalHyperParamsH(3), ...\n    optimalHyperParamsH(4), optimalHyperParamsH(5), mseDiameter, error(3));\nsaveas(gcf, filename);\n\nfilename = sprintf('../loop_05/01/nn_diameter-%d_iteration_%d_%d-%d-%d-%d-%d_mseDia-%d_test-%d.mat', diameterToRemove, i, ...\n    optimalHyperParamsH(1), optimalHyperParamsH(2), optimalHyperParamsH(3), ...\n    optimalHyperParamsH(4), optimalHyperParamsH(5), mseDiameter, error(3));\nsave(filename, 'bestTrainedNetH');\n\n\nWriting Results to CSV\nFinally, the results of the optimization are written to a CSV file for documentation:\nwritematrix([[\"Iteration\", \"Hidden Layer 1 Size\", \"Hidden Layer 2 Size\", \"Max Epochs\", ...\n    \"Training Function\", \"Activation Function\", \"Final MSE\", ...\n    \"Random Seed\", \"Training Error\", \"Validation Error\", \"Test Error\"]; result], './01/results_loop.csv');\n\ndisp('./01/Results saved to results_loop.csv');\n\n\nSupporting Functions\nSeveral supporting functions handle data loading, neural network optimization, and visualization:\nfunction [QH, D, QD, P] = loadData(dataPath)\n% Function to load data from specified path\n% ...\nend\n\nfunction [optimalHyperParams, finalMSE, randomSeed, bestTrainedNet, nnPerfVect] = optimizeNNForTrimmingPumpImpeller(x, t, userSeed, lowerBounds, upperBounds)\n% Function to optimize neural network hyperparameters using genetic algorithm\n% ...\nend\n\nfunction processDataAndVisualize(QH, D, QD, P, bestTrainedNetD, bestTrainedNetP, saveFigures)\n% Function to process data and generate visualizations\n% ...\nend"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html",
    "title": "Pump Trimming with AI: A Deep Dive into Theoretical and Engineering Aspects",
    "section": "",
    "text": "Pump trimming, a crucial process in fluid dynamics, involves adjusting the diameter of a pump’s impeller to optimize performance for specific flow rates and heads. Traditional methods, such as affinity laws, provide initial guidelines but often fall short in complex scenarios. With advancements in artificial intelligence (AI), specifically neural networks, more precise and adaptive models can be developed to improve pump efficiency and performance.\nIn this document, we explore the application of neural networks for pump trimming, focusing on the theoretical and engineering aspects. We will delve into the dataset preparation, neural network training, and performance evaluation, providing a comprehensive understanding of the methodology and the underlying principles."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#introduction",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#introduction",
    "title": "Pump Trimming with AI: A Deep Dive into Theoretical and Engineering Aspects",
    "section": "",
    "text": "Pump trimming, a crucial process in fluid dynamics, involves adjusting the diameter of a pump’s impeller to optimize performance for specific flow rates and heads. Traditional methods, such as affinity laws, provide initial guidelines but often fall short in complex scenarios. With advancements in artificial intelligence (AI), specifically neural networks, more precise and adaptive models can be developed to improve pump efficiency and performance.\nIn this document, we explore the application of neural networks for pump trimming, focusing on the theoretical and engineering aspects. We will delve into the dataset preparation, neural network training, and performance evaluation, providing a comprehensive understanding of the methodology and the underlying principles."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#dataset-preparation",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#dataset-preparation",
    "title": "Pump Trimming with AI: A Deep Dive into Theoretical and Engineering Aspects",
    "section": "Dataset Preparation",
    "text": "Dataset Preparation\nWe start by loading and preprocessing the datasets required for training and evaluation.\nclear; clc; clf; close all;\n\n% Load data\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\n% Extract data\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD = [filtered_QHD_table.Diameter_mm]';\nQH_beps = [deleted_QHD_table.FlowRate_m3h, deleted_QHD_table.Head_m]';\nD_beps = [deleted_QHD_table.Diameter_mm]';\nQD = [filtered_QDP_table.FlowRate_m3h, filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\nQD_beps = [deleted_QDP_table.FlowRate_m3h, deleted_QDP_table.Diameter_mm]';\nP_beps = [deleted_QDP_table.Power_kW]';\nThe datasets include various measurements of flow rate (Q), head (H), diameter (D), and power (P) for different pump configurations. By filtering and deleting specific entries, we create training and testing sets to evaluate the neural networks’ performance on unseen data."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#neural-network-architecture",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#neural-network-architecture",
    "title": "Pump Trimming with AI: A Deep Dive into Theoretical and Engineering Aspects",
    "section": "Neural Network Architecture",
    "text": "Neural Network Architecture\nWe employ feedforward neural networks (FNNs) with different architectures tailored for specific datasets (QHD, QDH, and QDP). The architectures are optimized using genetic algorithms (GA) to determine the best network structure and hyperparameters.\n% Hyperparameters based on latest optimization with GA\nrandomSeed = 4837;\nnn_QHD_size_matrix = [2, 16];\nnn_QDH_size_matrix = [2, 16];\nnn_QDP_size_matrix = [2, 7, 29, 17];\nmaxEpochs = 191;\ntrainFcn = 'trainlm';\n\nTraining the Networks\nWe train the neural networks on the full datasets to establish baseline performance metrics. The training function train_nn utilizes the Levenberg-Marquardt algorithm (trainlm) to minimize the mean squared error (MSE).\n% Train on full dataset\n[trainedNetQHD, avgMSEsQHD, trainPerformanceQHD, valPerformanceQHD, testPerformanceQHD] = train_nn(nn_QHD_size_matrix, maxEpochs, trainFcn, QH, D, randomSeed);\n[trainedNetQDH, avgMSEsQDH, trainPerformanceQDH, valPerformanceQDH, testPerformanceQDH] = train_nn(nn_QDH_size_matrix, maxEpochs, trainFcn, [QH(1,:); D], QH(2,:), randomSeed);\n[trainedNetQDP, avgMSEsQDP, trainPerformanceQDP, valPerformanceQDP, testPerformanceQDP] = train_nn(nn_QDP_size_matrix, maxEpochs, trainFcn, QD, P, randomSeed);"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#theoretical-background",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#theoretical-background",
    "title": "Pump Trimming with AI: A Deep Dive into Theoretical and Engineering Aspects",
    "section": "Theoretical Background",
    "text": "Theoretical Background\n\nNeural Networks in Pump Trimming\nNeural networks are particularly suitable for modeling complex nonlinear relationships in fluid dynamics. The key advantage is their ability to learn from data without explicit programming of the underlying physical laws. This makes them ideal for predicting pump performance across a wide range of operating conditions.\n\nNetwork Architecture\n\nInput Layer: Represents the features (e.g., flow rate, head, diameter) of the pump.\nHidden Layers: Capture the nonlinear relationships between input features and the output (e.g., head or power).\nOutput Layer: Provides the predicted value (e.g., optimized diameter).\n\nThe choice of the number of layers and neurons is critical. Too few neurons can lead to underfitting, while too many can cause overfitting. The GA helps in optimizing this balance.\n\n\n\nTraining and Optimization\nThe training process involves adjusting the weights of the neural network to minimize the MSE between the predicted and actual values. The Levenberg-Marquardt algorithm, a popular optimization technique, is used for this purpose due to its efficiency in handling large datasets and complex models."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#implementation-and-results",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#implementation-and-results",
    "title": "Pump Trimming with AI: A Deep Dive into Theoretical and Engineering Aspects",
    "section": "Implementation and Results",
    "text": "Implementation and Results\n\nRemoving Diameters and Training\nWe systematically remove each unique diameter from the dataset and train the neural network on the remaining data. This process helps in evaluating the network’s robustness and generalization capability.\n% Initialize results tables with headers\nQHD_results = array2table(NaN(1, 7), 'VariableNames', {'DiameterRemoved', 'AvgMSE', 'TrainPerformance', 'ValPerformance', 'TestPerformance', 'MSEDeletedDiameter', 'MSEBEPs'});\nQDP_results = array2table(NaN(1, 7), 'VariableNames', {'DiameterRemoved', 'AvgMSE', 'TrainPerformance', 'ValPerformance', 'TestPerformance', 'MSEDeletedDiameter', 'MSEBEPs'});\nQDH_results = array2table(NaN(1, 7), 'VariableNames', {'DiameterRemoved', 'AvgMSE', 'TrainPerformance', 'ValPerformance', 'TestPerformance', 'MSEDeletedDiameter', 'MSEBEPs'});\n\n% Weights for different errors\nweights = struct('train', 0.05, 'val', 0.05, 'test', 0.35, 'deleted_diameter', 0.45, 'beps', 0.1);\n\n% Function to compute the weighted score\ncompute_score = @(trainPerf, valPerf, testPerf, mseDeleted, mseBEPS, weights) ...\n    weights.train * trainPerf + weights.val * valPerf + weights.test * testPerf + weights.deleted_diameter * mseDeleted + weights.beps * mseBEPS;\n\n\nEvaluation and Visualization\nWe evaluate the performance of each network by computing the weighted score, which considers training, validation, and test performances along with errors on deleted diameters and BEP data.\n% Loop to train on different diameters hidden for QHD dataset\ndistinctDiametersQHD = unique(D);\nfor dIdx = 1:length(distinctDiametersQHD)\n    diameterToRemove = distinctDiametersQHD(dIdx);\n    indicesToRemove = find(D == diameterToRemove);\n    removedQH = QH(:, indicesToRemove);\n    removedD = D(indicesToRemove);\n    QH_temp = QH;\n    D_temp = D;\n    QH_temp(:, indicesToRemove) = [];\n    D_temp(:, indicesToRemove) = [];\n\n    try\n        [trainedNetQHD_temp, avgMSEsQHD_temp, trainPerformanceQHD_temp, valPerformanceQHD_temp, testPerformanceQHD_temp] = train_nn(nn_QHD_size_matrix, maxEpochs, trainFcn, QH_temp, D_temp, randomSeed);\n        mse_deleted_diameter = perform(trainedNetQHD_temp, removedD, trainedNetQHD_temp(removedQH));\n        mse_beps = perform(trainedNetQHD_temp, D_beps, trainedNetQHD_temp(QH_beps));\n        \n        % Compute the weighted score\n        score = compute_score(trainPerformanceQHD_temp, valPerformanceQHD_temp, testPerformanceQHD_temp, mse_deleted_diameter, mse_beps, weights);\n\n        % Update QHD_results\n        QHD_results = [QHD_results; {diameterToRemove, avgMSEsQHD_temp, trainPerformanceQHD_temp, valPerformanceQHD_temp, testPerformanceQHD_temp, mse_deleted_diameter, mse_beps}];\n\n        % Plot test data vs trained net predictions\n        figure;\n        plot(QH(1,:), QH(2,:), 'bo', 'DisplayName', 'Original Data'); % Original data\n        hold on;\n        plot(QH_temp(1,:), trainedNetQHD_temp([QH_temp(1,:); D_temp]), 'r*', 'DisplayName', 'Trained Net Predictions'); % Trained net predictions\n        plot(removedQH(1,:), removedQH(2,:), 'gx', 'DisplayName', 'Removed Diameter Data'); % Removed diameter data\n        plot(QH_beps(1,:), QH_beps(2,:), 'ms', 'DisplayName', 'BEPs Data'); % BEPs data\n        legend('Location', 'best');\n        title(['QHD: Diameter ' num2str(diameterToRemove)]);\n        xlabel('Flow Rate (m^3/h)');\n        ylabel('Head (m)');\n        xlim([0 400]);\n        ylim([0 90]);\n        grid on;\n        hold off;\n        saveas(gcf, fullfile('figures', ['QHD_Diameter_' num\n\n2str(diameterToRemove) '.png']));\n    catch ME\n        fprintf('Failed to train on diameter %d. Error: %s\\n', diameterToRemove, ME.message);\n    end\nend\nThe results are visualized by plotting the original data, trained network predictions, removed diameter data, and BEP data. This helps in understanding the network’s ability to generalize and accurately predict pump performance."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#conclusion",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_03.html#conclusion",
    "title": "Pump Trimming with AI: A Deep Dive into Theoretical and Engineering Aspects",
    "section": "Conclusion",
    "text": "Conclusion\nThe integration of AI, particularly neural networks, in pump trimming provides significant improvements over traditional methods. By leveraging data-driven models, we achieve higher accuracy and adaptability in predicting pump performance. This document serves as a detailed guide for researchers and engineers to implement and understand the theoretical and practical aspects of using AI in pump trimming."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#what-is-this-project-all-about",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#what-is-this-project-all-about",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "What is this Project All About",
    "text": "What is this Project All About\nProject Overview\n\nObjective: To optimize centrifugal pump performance through impeller trimming using AI.\nImportance: Enhances energy efficiency, reduces operational costs, and minimizes environmental impact."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#achieving-project-goals",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#achieving-project-goals",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Achieving Project Goals",
    "text": "Achieving Project Goals\nMethodology\n\nData Collection: Gather performance data of centrifugal pumps.\nAI Implementation: Develop neural networks to predict pump performance.\nOptimization: Use genetic algorithms for hyperparameter tuning."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#tools-used",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#tools-used",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Tools Used",
    "text": "Tools Used\nEssential Tools\n\nMATLAB: For implementing neural networks and genetic algorithms.\nPython: For data analysis and visualization.\nQuarto: For documentation and presentation."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#explanation-of-tools",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#explanation-of-tools",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Explanation of Tools",
    "text": "Explanation of Tools\nNeural Networks\n\nConcept: Neural networks model complex relationships between inputs (e.g., flow rate) and outputs (e.g., pump head).\nExample: Predicting pump head for a given flow rate and impeller diameter.\n\nSimple Example\ninputs: [flow_rate, impeller_diameter]\noutputs: [pump_head]\nGenetic Algorithms\n\nConcept: Optimization technique inspired by natural selection.\nExample: Finding the best hyperparameters for the neural network.\n\nSimple Example\npopulation: [[neurons_layer1, neurons_layer2], ...]\nfitness: mean_squared_error"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#performance-of-neural-networks",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#performance-of-neural-networks",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Performance of Neural Networks",
    "text": "Performance of Neural Networks\nEvaluation Metrics\n\nMean Squared Error (MSE): Measures prediction accuracy.\nTraining, Validation, and Test Performance: Assess generalization of the model.\n\nResults\nTrained Network Performance:\n- Training MSE: 0.001\n- Validation MSE: 0.002\n- Test MSE: 0.003"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#performance-of-traditional-trimming-methods",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#performance-of-traditional-trimming-methods",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Performance of Traditional Trimming Methods",
    "text": "Performance of Traditional Trimming Methods\nScaling Methods\n\nConstant-Area Scaling: Adjusts impeller diameter proportionally to maintain flow rate and head relationships.\n\nExample\nQ'/Q = D2'/D2\nH'/H = (D2'/D2)^2"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#engineering-value-of-this-project",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#engineering-value-of-this-project",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Engineering Value of This Project",
    "text": "Engineering Value of This Project\nBenefits\n\nEnergy Efficiency: Reduces energy consumption by optimizing pump performance.\nCost Savings: Lowers operational costs by minimizing energy wastage.\nEnvironmental Impact: Decreases greenhouse gas emissions by saving energy."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#effect-of-trimming-on-energy-consumption-and-pollution-reduction",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#effect-of-trimming-on-energy-consumption-and-pollution-reduction",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Effect of Trimming on Energy Consumption and Pollution Reduction",
    "text": "Effect of Trimming on Energy Consumption and Pollution Reduction\nEnergy Savings\n\nEfficiency Gains: Trimming impeller to match system requirements improves efficiency.\nImpact: For each kW saved in pump delivery, approximately 6 kWh is saved at the power station.\n\nPollution Reduction\n\nCorrelation: Reduced energy consumption leads to lower emissions.\nExample: Each kWh saved translates to significant reductions in power station output and pollution."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#neural-networks-and-hyperparameter-optimization",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#neural-networks-and-hyperparameter-optimization",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Neural Networks and Hyperparameter Optimization",
    "text": "Neural Networks and Hyperparameter Optimization\nNeural Network Architecture\n\nComponents: Input layer, hidden layers, output layer.\nTraining Process: Adjusting weights to minimize error.\n\nHyperparameters\n\nDefinition: Settings adjusted before training.\nExamples: Number of neurons, epochs, activation functions.\n\nGenetic Algorithm for Optimization\n\nProcess:\n\nInitialization: Generate initial population.\nSelection: Choose best individuals.\nCrossover: Combine individuals to create offspring.\nMutation: Introduce variations.\nEvaluation: Assess fitness and iterate.\n\n\nMATLAB Implementation\n% Genetic algorithm options\ngaOptions = optimoptions('ga', ...\n    'PopulationSize', 17, ...\n    'MaxGenerations', 13, ...\n    'CrossoverFraction', 0.8, ...\n    'FitnessLimit', 0.000991, ...\n    'EliteCount', 2, ...\n    'Display', 'iter', ...\n    'UseParallel', true);\n\n% Optimization using genetic algorithm\n[optimalHyperParams, finalMSE] = ga(@(hyperParams) evaluateHyperparameters(hyperParams, x, t, randomSeed), ...\n    length(lower_bounds), [], [], [], [], lower_bounds, upper_bounds, [], gaOptions);"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#comparison-with-traditional-methods",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#comparison-with-traditional-methods",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Comparison with Traditional Methods",
    "text": "Comparison with Traditional Methods\nErrors and Reductions\n\nError Analysis: Compare errors in predictions by neural networks and traditional methods.\nReductions: Analyze the percent reduction in diameter and its impact.\n\nResults\nErrors and Reductions:\n- Traditional Method Error: 10%\n- Neural Network Error: 1%\n- Percent Reduction: 5%"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#creative-thoughts-and-further-directions",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#creative-thoughts-and-further-directions",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Creative Thoughts and Further Directions",
    "text": "Creative Thoughts and Further Directions\nFuture Enhancements\n\nData Integration: Incorporate real-time data for dynamic adjustments.\nAdvanced Models: Explore deep learning for more complex predictions.\nWider Applications: Extend methodology to other types of pumps and industrial equipment."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#conclusion",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation_02.html#conclusion",
    "title": "Prediction of the Effect of Impeller Trimming on Centrifugal Pump Performance Using AI",
    "section": "Conclusion",
    "text": "Conclusion\nSummary\n\nAI Advantage: Neural networks and genetic algorithms significantly improve prediction accuracy and efficiency.\nEnvironmental Impact: Optimized pump performance contributes to energy savings and pollution reduction.\nFuture Potential: Continuous improvement and application expansion can further enhance industrial efficiency and sustainability."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#project-overview",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#project-overview",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Project Overview",
    "text": "Project Overview\nWhat is this project all about?\nThis project aims to optimize the trimming of pump impeller diameters using neural networks.\nIt compares the performance of neural networks with traditional trimming methods in predicting the correct diameter for efficient pump operation."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#project-goals",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#project-goals",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Project Goals",
    "text": "Project Goals\n\nbuild code that is capable of search for optimal neural network architecture using genetic algorithms (using matlab ga).\ncompare NNs with traditional scaling based methods as in weme paper"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#how-will-it-achieve-its-goals",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#how-will-it-achieve-its-goals",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "How will it achieve its goals?",
    "text": "How will it achieve its goals?\n\nTrain neural networks on existing pump performance data.\ncreate loop to hide a one curve and use it for testing in addition to the beps.\nEvaluate the trained models on new data points (beps) with best efficiency points used for testing performance of NNs we build.\nCompare the neural network predictions to traditional trimming methods."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#tools-used",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#tools-used",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Tools Used",
    "text": "Tools Used"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#tools-it-will-use",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#tools-it-will-use",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Tools it will use",
    "text": "Tools it will use\n\nMATLAB ga toolbox.\nMATLAB Neural Network Toolbox in MATLAB.\nTraditional trimming methods: Constant Area Scaling (weme paper) and nearest diameter method (this our convention of largest diameter being the master)."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#neural-networks---theory",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#neural-networks---theory",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Neural Networks - Theory",
    "text": "Neural Networks - Theory"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#neural-networks-explained",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#neural-networks-explained",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Neural Networks Explained",
    "text": "Neural Networks Explained\n\nNeural networks are composed of layers of interconnected nodes.\nEach node applies a weighted sum followed by a non-linear activation function.\nThe network is trained using a dataset to minimize the error in predictions."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#example",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#example",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Example",
    "text": "Example\n\nInput Layer: Receives input data (e.g., flow rate, head).\nHidden Layers: Perform transformations on the data.\nOutput Layer: Produces the prediction (e.g., trimmed diameter).\nEpochs: number of iterations."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#traditional-trimming-methods---theory",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#traditional-trimming-methods---theory",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Traditional Trimming Methods - Theory",
    "text": "Traditional Trimming Methods - Theory\nConstant Area Scaling\n\nAdjusts the impeller diameter while maintaining a constant area ratio.\nTraditional method used for scaling pump performance.\n\nNearest Diameter Method\n\nChooses the nearest available diameter from a predefined set based on performance criteria."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#neural-network-performance",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#neural-network-performance",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Neural Network Performance",
    "text": "Neural Network Performance"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#performance-of-the-neural-networks",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#performance-of-the-neural-networks",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Performance of the Neural Networks",
    "text": "Performance of the Neural Networks\n\nTraining and testing neural networks with various architectures.\nEvaluating on metrics like Mean Squared Error (MSE).\nResults show how well the network predicts the trimmed diameters."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#traditional-methods-performance",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#traditional-methods-performance",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Traditional Methods Performance",
    "text": "Traditional Methods Performance"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#performance-of-traditional-trimming-methods",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#performance-of-traditional-trimming-methods",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Performance of Traditional Trimming Methods",
    "text": "Performance of Traditional Trimming Methods\n\nComparison with Constant Area Scaling and nearest diameter method.\nErrors are calculated as the difference between the predicted and actual diameters."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#here-is-example-fit",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#here-is-example-fit",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "here is example fit",
    "text": "here is example fit\n\nbest nn over all view"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#qhd-results-table",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#qhd-results-table",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "QHD results table",
    "text": "QHD results table\n\n\n\n\n\n\n\n\n\nDiameterRemoved\nAvgMSE\nTrainPerformance\nValPerformance\nTestPerformance\nMSEDeletedDiameter\nMSEBEPs\n\n\n\n\n0\n230\n0.025035\n0.006973\n0.013087\n0.063566\n13.109880\n0.887325\n\n\n1\n240\n0.002054\n0.001905\n0.002182\n0.002146\n0.174083\n0.033176\n\n\n2\n250\n0.003343\n0.002433\n0.004716\n0.003316\n0.626366\n0.015352\n\n\n3\n260\n0.002077\n0.001944\n0.001985\n0.002364\n23.101650\n0.330787"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#qdp-results-table",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#qdp-results-table",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "QDP results table",
    "text": "QDP results table\n\n\n\n\n\n\n\n\n\nDiameterRemoved\nAvgMSE\nTrainPerformance\nValPerformance\nTestPerformance\nMSEDeletedDiameter\nMSEBEPs\n\n\n\n\n0\n230\n1.061458\n1.074642\n1.005925\n1.097531\n1.459545\n0.504712\n\n\n1\n240\n0.856944\n0.717666\n0.856781\n1.062996\n2.272058\n0.855605\n\n\n2\n250\n0.001608\n0.001304\n0.001949\n0.001718\n11.410656\n0.001787\n\n\n3\n260\n0.001312\n0.001193\n0.001446\n0.001355\n3.709925\n0.001861"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#qdh-results-tabel",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#qdh-results-tabel",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "QDH results tabel",
    "text": "QDH results tabel\n\n\n\n\n\n\n\n\n\nDiameterRemoved\nAvgMSE\nTrainPerformance\nValPerformance\nTestPerformance\nMSEDeletedDiameter\nMSEBEPs\n\n\n\n\n0\n230\n0.003924\n0.002607\n0.002910\n0.006876\n0.030449\n0.001832\n\n\n1\n240\n2.324643\n2.171064\n2.720251\n2.155551\n22.142540\n4.378357\n\n\n2\n250\n0.002601\n0.001929\n0.003371\n0.002826\n781.213228\n201.866566\n\n\n3\n260\n0.002949\n0.002372\n0.004189\n0.002559\n5.875235\n0.017837"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#nns-errors-comparisons-with-traditional-trimming-and-reductions-in-diameter",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#nns-errors-comparisons-with-traditional-trimming-and-reductions-in-diameter",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "NNs errors comparisons with traditional trimming and reductions in Diameter",
    "text": "NNs errors comparisons with traditional trimming and reductions in Diameter"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#comparison",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#comparison",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "comparison",
    "text": "comparison\n\n\n\n\n\n\n\n\n\nIndex\nPercent_Error_CAS_260\nPercent_Error_CAS_Nearest\nPercent_Error_NN\nPercent_Reduction\n\n\n\n\n0\n1\n241.145202\n3.261635\n2.541009\n2.541009\n\n\n1\n2\n241.798697\n3.076349\n3.588867\n3.588867\n\n\n2\n3\n238.978142\n8.063994\n3.085461\n3.085461\n\n\n3\n4\n228.293618\n1.351752\n2.207965\n2.207965\n\n\n4\n5\n245.536126\n3.828971\n2.299324\n2.299324"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#final-comparison-statistics",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#final-comparison-statistics",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "final comparison statistics",
    "text": "final comparison statistics\n\n\n\n\n\n\n\n\n\nMAE_Trim_Diameters\nMAE_TrainedNetQHD\nCount_Better_TrainedNetQHD\nCount_Better_Trim_Diameters\n\n\n\n\n0\n3.91654\n2.744525\n3\n2"
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#engineering-value",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#engineering-value",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Engineering Value",
    "text": "Engineering Value\nThe Engineering Value of This Project\n\nAccurate prediction of trimmed diameters enhances pump efficiency.\nReduces the need for physical trials, saving time and resources."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#environmental-impact",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#environmental-impact",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Environmental Impact",
    "text": "Environmental Impact\nEffect of Trimming on Energy Consumption and Pollution Reduction\n\nOptimized trimming leads to energy-efficient pump operation.\nLower energy consumption results in reduced greenhouse gas emissions. where each 1 kw reduction in pump delivery corresponds to 6 kwhr in the power station."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#future-directions",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#future-directions",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Future Directions",
    "text": "Future Directions\n\nExtend the neural network model to predict other performance metrics.\nIntegrate real-time data for dynamic trimming adjustments.\nExplore other machine learning algorithms for comparison."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#results-and-conclusion",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/presentation.html#results-and-conclusion",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "Results and Conclusion",
    "text": "Results and Conclusion\nResults\n\nNeural networks outperform traditional methods in all cases.\nSignificant reduction in error rates and improved accuracy.\n\nConclusion\n\nNeural networks offer a promising alternative for impeller diameter trimming.\nFurther research and real-world testing can enhance the reliability and applicability of these models."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Centrifugal pumps are pivotal components in various industrial applications, from water supply systems to chemical processing. Optimizing their performance is crucial for enhancing energy efficiency and reducing operational costs. One key optimization technique is impeller trimming, which involves reducing the diameter of a pump impeller to align the pump’s performance more closely with the system requirements. This chapter explores the concept of impeller trimming, its significance, traditional methods, and the advantages of employing Artificial Intelligence (AI) for performance prediction.\n\n\n\n\n\nImpeller trimming is the process of mechanically reducing the diameter of the pump impeller. This adjustment directly influences the pump’s head and flow rate, thereby modifying its performance characteristics. Trimming is performed to ensure that the pump operates within the desired performance range, avoiding over-delivery or under-delivery of fluid.\n\n\n\nImpeller trimming is essential for several reasons: 1. Energy Consumption: Proper trimming ensures that the pump operates at its optimal efficiency point, significantly reducing energy consumption. Each kilowatt saved at the pump level translates to approximately six kilowatts saved at the power station. 2. Market Availability: Pumps available in the market may not always fit specific system requirements precisely. Trimming provides a means to tailor the pump’s performance to meet these specific needs.\n\n\n\n\nImpeller trimming is not only beneficial for energy savings but also contributes to environmental sustainability. Reduced energy consumption leads to lower greenhouse gas emissions. For every kilowatt-hour (kWh) saved by the pump, the reduction in power station output significantly decreases pollution, making trimming an environmentally responsible practice.\n\n\n\n\n\nInstead of relying solely on empirical formulas and performance curves derived from extensive testing, scaling methods provide a mathematical approach to predicting the performance of a trimmed impeller. One such method is constant-area scaling, which assumes that the trimmed impeller maintains a constant area, ensuring proportional changes in flow and head.\n\n\nConstant-area scaling involves adjusting the impeller diameter while maintaining the proportional relationship between the flow rate and head. This method ensures that the trimmed impeller operates efficiently within the desired performance range, without significant deviations from the original design.\nThe constant-area scaling method is defined by the following relationship:\n[ D_{trimmed} = D_{original} ()^{1/2} ]\nWhere: - ( D_{trimmed} ) is the diameter of the trimmed impeller. - ( D_{original} ) is the original diameter of the impeller. - ( Q_{trimmed} ) is the desired flow rate after trimming. - ( Q_{original} ) is the original flow rate.\n\n\n\n\nTrimming the impeller allows for the customization of pump performance to meet specific operational requirements. This customization is particularly necessary when: - The available pump sizes do not perfectly match the required system specifications. - System demands change over time, necessitating adjustments to maintain optimal efficiency. - Reducing the operational costs by minimizing energy wastage.\n\n\n\n\nArtificial Neural Networks (ANNs) offer a robust alternative to traditional methods by leveraging large datasets to predict pump performance accurately. Unlike empirical methods, ANNs can model complex, non-linear relationships between variables, providing more precise predictions.\n\n\n\nAccuracy: ANNs can learn from vast amounts of data, capturing intricate patterns and relationships that traditional methods might miss.\nEfficiency: Once trained, ANNs can quickly predict performance outcomes for different impeller diameters, saving time and resources.\nAdaptability: Neural networks can be updated with new data, continuously improving their predictive capabilities.\n\n\n\n\n\nThe implementation of AI for impeller trimming was carried out using MATLAB. The scripts main_04.m and QHforDiameters.m are critical components of this implementation, leveraging optimized neural network architectures to predict pump performance based on different impeller diameters.\n\n\nThe main_04.m script incorporates the following key steps:\n\nData Loading: Loading datasets containing flow rate, head, diameter, and power metrics.\nNetwork Training: Training neural networks with optimized architectures to predict head and power based on flow rate and diameter.\nPerformance Evaluation: Evaluating the trained networks on various performance metrics to ensure accuracy and reliability.\nVisualization: Generating 3D plots to visualize the relationship between flow rate, head, diameter, and power, showcasing the neural network predictions versus actual data.\n\n\n\n\ntrain_nn: This function trains the neural network using the provided data, returning the trained model and performance metrics.\ntrim_diameters: This function determines the optimal trimmed diameter based on the provided pump data and performance criteria.\nprocessDataAndVisualize: This function processes the data and generates visualizations to compare neural network predictions with actual data points.\n\n\n\n\nThe following MATLAB code snippet from main_04.m demonstrates how to load data, train neural networks, and visualize the results:\nclear; clc; clf; close all;\n\n% Load data\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\n% Extract data\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD = [filtered_QHD_table.Diameter_mm]';\nQD = [filtered_QDP_table.FlowRate_m3h, filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\n% Train on full dataset\n[trainedNetQHD, ~, ~, ~, ~] = train_nn([2, 16], 191, 'trainlm', QH, D, 4837);\n[trainedNetQDP, ~, ~, ~, ~] = train_nn([2, 7, 29, 17], 191, 'trainlm', QD, P, 4837);\n\n% Visualization\nprocessDataAndVisualize(QH', D', QD', P', trainedNetQHD, trainedNetQDP, 'figures');\nIn this script, data is first loaded from various .mat files. The train_nn function is used to train neural networks on the flow rate and head data (QH) and diameter (D). The processDataAndVisualize function then generates visualizations to compare neural network predictions with actual data points.\n\n\n\n\nThe QHforDiameters.m script focuses on optimizing neural network hyperparameters for better performance prediction. It uses a genetic algorithm to find the optimal neural network architecture, ensuring accurate predictions for different impeller diameters.\n\n\n\nInitialization: Loading data and initializing variables.\nHyperparameter Optimization: Using a genetic algorithm to find the optimal neural network architecture.\nPerformance Evaluation: Assessing the neural network’s performance on the training and test datasets.\nVisualization: Plotting the predicted performance curves for different impeller diameters.\n\n\n\n\nThe following MATLAB code snippet from QHforDiameters.m illustrates the process of optimizing neural network hyperparameters and visualizing the results:\nclear; clc; clf;\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD  = [filtered_QHD_table.Diameter_mm]';\n\nQH_beps=[deleted_QHD_table.FlowRate_m3h,deleted_QHD_table.Head_m]';\nD_beps=[deleted_QHD_table.Diameter_mm]';\n\nQD = [filtered_QDP_table.FlowRate_m3h,filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\nQD_beps=[deleted_QDP_table.FlowRate_m3h,deleted_QDP_table.Diameter_mm]';\nP_beps=[deleted_QDP_table.Power_kW]';\n\n% User-specified random seed (optional)\nuserSeed = 4826;\n\n% Define a threshold for MSE to exit the loop early\nmseThreshold = 0.000199;\n\n% Initialize result matrix\nresult = [];\n\n% Find all distinct diameters in D\ndistinctDiameters = unique(D);\n\n% Weights for combining MSEs\nweightDiameter = 0.5;\nweightBeps = 0.5;\n\nfor dIdx = 1:length(distinctDiameters)\n    % Current diameter to remove\n    diameterToRemove = distinctDiam\n\neters(dIdx);\n    \n    % Remove the current diameter from QH and D\n    idxToKeep = D ~= diameterToRemove;\n    QH_filtered = QH(:, idxToKeep);\n    D_filtered = D(idxToKeep);\n    \n    % Calculate the number of epochs based on dataset size\n    maxEpochs = 1000 + floor(size(QH_filtered, 2) / 10);\n    \n    % Determine the number of hidden layers and neurons to search\n    hiddenLayers = [1:10];\n    neuronsPerLayer = [1:30];\n    \n    % Initialize the best MSE and corresponding architecture\n    bestMSE = Inf;\n    bestArch = [];\n    \n    % Random seed for reproducibility\n    rng(userSeed);\n    \n    for hl = hiddenLayers\n        for np = neuronsPerLayer\n            % Define the neural network architecture\n            netArch = [repmat(np, 1, hl), 1];\n            \n            % Train the neural network\n            [trainedNet, trainPerformance, ~, ~, ~] = train_nn(netArch, maxEpochs, 'trainlm', QH_filtered, D_filtered, userSeed);\n            \n            % Calculate the Mean Squared Error (MSE) on the removed data\n            QH_beps_pred = trainedNet(QH_beps);\n            mse_beps = mean((QH_beps_pred - D_beps).^2);\n            \n            % Calculate the weighted MSE\n            weightedMSE = weightDiameter * trainPerformance.best_perf + weightBeps * mse_beps;\n            \n            % Update the best architecture if current MSE is lower\n            if weightedMSE &lt; bestMSE\n                bestMSE = weightedMSE;\n                bestArch = netArch;\n            end\n            \n            % Exit loop early if the MSE is below the threshold\n            if weightedMSE &lt; mseThreshold\n                break;\n            end\n        end\n        \n        % Exit loop early if the MSE is below the threshold\n        if bestMSE &lt; mseThreshold\n            break;\n        end\n    end\n    \n    % Store the result for the current diameter\n    result = [result; diameterToRemove, bestArch, bestMSE];\nend\n\n% Display the best architectures for each removed diameter\ndisp('Best architectures for each removed diameter:');\ndisp(result);\n\n% Save the result to a file\nsave('best_architectures.mat', 'result');\nIn this script, data is loaded from various .mat files, and a genetic algorithm is used to find the optimal neural network architecture for predicting pump performance based on different impeller diameters. The script evaluates the performance of the trained networks and visualizes the results to ensure accuracy.\n\n\n\n\n\nImpeller trimming is a crucial technique for optimizing centrifugal pump performance, leading to significant energy savings and reduced environmental impact. Traditional methods, while useful, have limitations in accuracy and adaptability. Artificial Neural Networks (ANNs) provide a superior alternative by accurately predicting the effects of trimming, thus enabling better decision-making and operational efficiency. The MATLAB scripts main_04.m and QHforDiameters.m demonstrate the practical implementation of AI in predicting pump performance, highlighting the potential of this approach in real-world applications."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#introduction",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#introduction",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Centrifugal pumps are pivotal components in various industrial applications, from water supply systems to chemical processing. Optimizing their performance is crucial for enhancing energy efficiency and reducing operational costs. One key optimization technique is impeller trimming, which involves reducing the diameter of a pump impeller to align the pump’s performance more closely with the system requirements. This chapter explores the concept of impeller trimming, its significance, traditional methods, and the advantages of employing Artificial Intelligence (AI) for performance prediction."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#the-concept-of-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#the-concept-of-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Impeller trimming is the process of mechanically reducing the diameter of the pump impeller. This adjustment directly influences the pump’s head and flow rate, thereby modifying its performance characteristics. Trimming is performed to ensure that the pump operates within the desired performance range, avoiding over-delivery or under-delivery of fluid.\n\n\n\nImpeller trimming is essential for several reasons: 1. Energy Consumption: Proper trimming ensures that the pump operates at its optimal efficiency point, significantly reducing energy consumption. Each kilowatt saved at the pump level translates to approximately six kilowatts saved at the power station. 2. Market Availability: Pumps available in the market may not always fit specific system requirements precisely. Trimming provides a means to tailor the pump’s performance to meet these specific needs."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#energy-savings-and-environmental-impact",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#energy-savings-and-environmental-impact",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Impeller trimming is not only beneficial for energy savings but also contributes to environmental sustainability. Reduced energy consumption leads to lower greenhouse gas emissions. For every kilowatt-hour (kWh) saved by the pump, the reduction in power station output significantly decreases pollution, making trimming an environmentally responsible practice."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#traditional-methods-of-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#traditional-methods-of-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Instead of relying solely on empirical formulas and performance curves derived from extensive testing, scaling methods provide a mathematical approach to predicting the performance of a trimmed impeller. One such method is constant-area scaling, which assumes that the trimmed impeller maintains a constant area, ensuring proportional changes in flow and head.\n\n\nConstant-area scaling involves adjusting the impeller diameter while maintaining the proportional relationship between the flow rate and head. This method ensures that the trimmed impeller operates efficiently within the desired performance range, without significant deviations from the original design.\nThe constant-area scaling method is defined by the following relationship:\n[ D_{trimmed} = D_{original} ()^{1/2} ]\nWhere: - ( D_{trimmed} ) is the diameter of the trimmed impeller. - ( D_{original} ) is the original diameter of the impeller. - ( Q_{trimmed} ) is the desired flow rate after trimming. - ( Q_{original} ) is the original flow rate.\n\n\n\n\nTrimming the impeller allows for the customization of pump performance to meet specific operational requirements. This customization is particularly necessary when: - The available pump sizes do not perfectly match the required system specifications. - System demands change over time, necessitating adjustments to maintain optimal efficiency. - Reducing the operational costs by minimizing energy wastage."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#artificial-neural-networks-for-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#artificial-neural-networks-for-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Artificial Neural Networks (ANNs) offer a robust alternative to traditional methods by leveraging large datasets to predict pump performance accurately. Unlike empirical methods, ANNs can model complex, non-linear relationships between variables, providing more precise predictions.\n\n\n\nAccuracy: ANNs can learn from vast amounts of data, capturing intricate patterns and relationships that traditional methods might miss.\nEfficiency: Once trained, ANNs can quickly predict performance outcomes for different impeller diameters, saving time and resources.\nAdaptability: Neural networks can be updated with new data, continuously improving their predictive capabilities."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#implementation-in-matlab",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#implementation-in-matlab",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "The implementation of AI for impeller trimming was carried out using MATLAB. The scripts main_04.m and QHforDiameters.m are critical components of this implementation, leveraging optimized neural network architectures to predict pump performance based on different impeller diameters.\n\n\nThe main_04.m script incorporates the following key steps:\n\nData Loading: Loading datasets containing flow rate, head, diameter, and power metrics.\nNetwork Training: Training neural networks with optimized architectures to predict head and power based on flow rate and diameter.\nPerformance Evaluation: Evaluating the trained networks on various performance metrics to ensure accuracy and reliability.\nVisualization: Generating 3D plots to visualize the relationship between flow rate, head, diameter, and power, showcasing the neural network predictions versus actual data.\n\n\n\n\ntrain_nn: This function trains the neural network using the provided data, returning the trained model and performance metrics.\ntrim_diameters: This function determines the optimal trimmed diameter based on the provided pump data and performance criteria.\nprocessDataAndVisualize: This function processes the data and generates visualizations to compare neural network predictions with actual data points.\n\n\n\n\nThe following MATLAB code snippet from main_04.m demonstrates how to load data, train neural networks, and visualize the results:\nclear; clc; clf; close all;\n\n% Load data\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\n% Extract data\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD = [filtered_QHD_table.Diameter_mm]';\nQD = [filtered_QDP_table.FlowRate_m3h, filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\n% Train on full dataset\n[trainedNetQHD, ~, ~, ~, ~] = train_nn([2, 16], 191, 'trainlm', QH, D, 4837);\n[trainedNetQDP, ~, ~, ~, ~] = train_nn([2, 7, 29, 17], 191, 'trainlm', QD, P, 4837);\n\n% Visualization\nprocessDataAndVisualize(QH', D', QD', P', trainedNetQHD, trainedNetQDP, 'figures');\nIn this script, data is first loaded from various .mat files. The train_nn function is used to train neural networks on the flow rate and head data (QH) and diameter (D). The processDataAndVisualize function then generates visualizations to compare neural network predictions with actual data points.\n\n\n\n\nThe QHforDiameters.m script focuses on optimizing neural network hyperparameters for better performance prediction. It uses a genetic algorithm to find the optimal neural network architecture, ensuring accurate predictions for different impeller diameters.\n\n\n\nInitialization: Loading data and initializing variables.\nHyperparameter Optimization: Using a genetic algorithm to find the optimal neural network architecture.\nPerformance Evaluation: Assessing the neural network’s performance on the training and test datasets.\nVisualization: Plotting the predicted performance curves for different impeller diameters.\n\n\n\n\nThe following MATLAB code snippet from QHforDiameters.m illustrates the process of optimizing neural network hyperparameters and visualizing the results:\nclear; clc; clf;\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD  = [filtered_QHD_table.Diameter_mm]';\n\nQH_beps=[deleted_QHD_table.FlowRate_m3h,deleted_QHD_table.Head_m]';\nD_beps=[deleted_QHD_table.Diameter_mm]';\n\nQD = [filtered_QDP_table.FlowRate_m3h,filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\nQD_beps=[deleted_QDP_table.FlowRate_m3h,deleted_QDP_table.Diameter_mm]';\nP_beps=[deleted_QDP_table.Power_kW]';\n\n% User-specified random seed (optional)\nuserSeed = 4826;\n\n% Define a threshold for MSE to exit the loop early\nmseThreshold = 0.000199;\n\n% Initialize result matrix\nresult = [];\n\n% Find all distinct diameters in D\ndistinctDiameters = unique(D);\n\n% Weights for combining MSEs\nweightDiameter = 0.5;\nweightBeps = 0.5;\n\nfor dIdx = 1:length(distinctDiameters)\n    % Current diameter to remove\n    diameterToRemove = distinctDiam\n\neters(dIdx);\n    \n    % Remove the current diameter from QH and D\n    idxToKeep = D ~= diameterToRemove;\n    QH_filtered = QH(:, idxToKeep);\n    D_filtered = D(idxToKeep);\n    \n    % Calculate the number of epochs based on dataset size\n    maxEpochs = 1000 + floor(size(QH_filtered, 2) / 10);\n    \n    % Determine the number of hidden layers and neurons to search\n    hiddenLayers = [1:10];\n    neuronsPerLayer = [1:30];\n    \n    % Initialize the best MSE and corresponding architecture\n    bestMSE = Inf;\n    bestArch = [];\n    \n    % Random seed for reproducibility\n    rng(userSeed);\n    \n    for hl = hiddenLayers\n        for np = neuronsPerLayer\n            % Define the neural network architecture\n            netArch = [repmat(np, 1, hl), 1];\n            \n            % Train the neural network\n            [trainedNet, trainPerformance, ~, ~, ~] = train_nn(netArch, maxEpochs, 'trainlm', QH_filtered, D_filtered, userSeed);\n            \n            % Calculate the Mean Squared Error (MSE) on the removed data\n            QH_beps_pred = trainedNet(QH_beps);\n            mse_beps = mean((QH_beps_pred - D_beps).^2);\n            \n            % Calculate the weighted MSE\n            weightedMSE = weightDiameter * trainPerformance.best_perf + weightBeps * mse_beps;\n            \n            % Update the best architecture if current MSE is lower\n            if weightedMSE &lt; bestMSE\n                bestMSE = weightedMSE;\n                bestArch = netArch;\n            end\n            \n            % Exit loop early if the MSE is below the threshold\n            if weightedMSE &lt; mseThreshold\n                break;\n            end\n        end\n        \n        % Exit loop early if the MSE is below the threshold\n        if bestMSE &lt; mseThreshold\n            break;\n        end\n    end\n    \n    % Store the result for the current diameter\n    result = [result; diameterToRemove, bestArch, bestMSE];\nend\n\n% Display the best architectures for each removed diameter\ndisp('Best architectures for each removed diameter:');\ndisp(result);\n\n% Save the result to a file\nsave('best_architectures.mat', 'result');\nIn this script, data is loaded from various .mat files, and a genetic algorithm is used to find the optimal neural network architecture for predicting pump performance based on different impeller diameters. The script evaluates the performance of the trained networks and visualizes the results to ensure accuracy."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#conclusion",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_02.html#conclusion",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Impeller trimming is a crucial technique for optimizing centrifugal pump performance, leading to significant energy savings and reduced environmental impact. Traditional methods, while useful, have limitations in accuracy and adaptability. Artificial Neural Networks (ANNs) provide a superior alternative by accurately predicting the effects of trimming, thus enabling better decision-making and operational efficiency. The MATLAB scripts main_04.m and QHforDiameters.m demonstrate the practical implementation of AI in predicting pump performance, highlighting the potential of this approach in real-world applications."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Centrifugal pumps are integral components in various industrial applications, ranging from water supply systems to chemical processing. Optimizing their performance is crucial for enhancing energy efficiency and reducing operational costs. One key optimization technique is impeller trimming, which involves reducing the diameter of a pump impeller to align the pump’s performance more closely with the system requirements. This chapter explores the concept of impeller trimming, its significance, traditional methods, and the advantages of employing Artificial Intelligence (AI) for performance prediction.\n\n\n\n\n\nImpeller trimming is the process of mechanically reducing the diameter of the pump impeller. This adjustment directly influences the pump’s head and flow rate, thereby modifying its performance characteristics. Trimming is performed to ensure that the pump operates within the desired performance range, avoiding over-delivery or under-delivery of fluid.\n\n\n\nImpeller trimming is essential for several reasons: 1. Energy Consumption: Proper trimming ensures that the pump operates at its optimal efficiency point, significantly reducing energy consumption. Each kilowatt saved at the pump level translates to approximately six kilowatts saved at the power station. 2. Market Availability: Pumps available in the market may not always fit specific system requirements precisely. Trimming provides a means to tailor the pump’s performance to meet these specific needs.\n\n\n\n\nImpeller trimming is not only beneficial for energy savings but also contributes to environmental sustainability. Reduced energy consumption leads to lower greenhouse gas emissions. For every kilowatt-hour (kWh) saved by the pump, the reduction in power station output significantly decreases pollution, making trimming an environmentally responsible practice.\n\n\n\n\n\nInstead of relying solely on empirical formulas and performance curves derived from extensive testing, scaling methods provide a mathematical approach to predicting the performance of a trimmed impeller. One such method is constant-area scaling, which assumes that the trimmed impeller maintains a constant area, ensuring proportional changes in flow and head.\n\n\nConstant-area scaling involves adjusting the impeller diameter while maintaining the proportional relationship between the flow rate and head. This method ensures that the trimmed impeller operates efficiently within the desired performance range, without significant deviations from the original design.\nThe constant-area scaling method is defined by the following relationship:\n[ D_{trimmed} = D_{original} ()^{1/2} ]\nWhere: - ( D_{trimmed} ) is the diameter of the trimmed impeller. - ( D_{original} ) is the original diameter of the impeller. - ( Q_{trimmed} ) is the desired flow rate after trimming. - ( Q_{original} ) is the original flow rate.\n\n\n\n\n\nArtificial Neural Networks (ANNs) offer a robust alternative to traditional methods by leveraging large datasets to predict pump performance accurately. Unlike empirical methods, ANNs can model complex, non-linear relationships between variables, providing more precise predictions.\n\n\n\nAccuracy: ANNs can learn from vast amounts of data, capturing intricate patterns and relationships that traditional methods might miss.\nEfficiency: Once trained, ANNs can quickly predict performance outcomes for different impeller diameters, saving time and resources.\nAdaptability: Neural networks can be updated with new data, continuously improving their predictive capabilities.\n\n\n\n\nThe implementation of AI for impeller trimming was carried out using MATLAB. The scripts main_04.m and QHforDiameters.m are critical components of this implementation, leveraging optimized neural network architectures to predict pump performance based on different impeller diameters.\n\n\nThe main_04.m script incorporates the following key steps:\n\nData Loading: Loading datasets containing flow rate, head, diameter, and power metrics.\nNetwork Training: Training neural networks with optimized architectures to predict head and power based on flow rate and diameter.\nPerformance Evaluation: Evaluating the trained networks on various performance metrics to ensure accuracy and reliability.\nVisualization: Generating 3D plots to visualize the relationship between flow rate, head, diameter, and power, showcasing the neural network predictions versus actual data.\n\n\n\n\ntrain_nn: This function trains the neural network using the provided data, returning the trained model and performance metrics.\ntrim_diameters: This function determines the optimal trimmed diameter based on the provided pump data and performance criteria.\nprocessDataAndVisualize: This function processes the data and generates visualizations to compare neural network predictions with actual data points.\n\n\n\n\nThe following MATLAB code snippet from main_04.m demonstrates how to load data, train neural networks, and visualize the results:\nclear; clc; clf; close all;\n\n% Load data\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\n% Extract data\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD = [filtered_QHD_table.Diameter_mm]';\nQD = [filtered_QDP_table.FlowRate_m3h, filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\n% Train on full dataset\n[trainedNetQHD, ~, ~, ~, ~] = train_nn([2, 16], 191, 'trainlm', QH, D, 4837);\n[trainedNetQDP, ~, ~, ~, ~] = train_nn([2, 7, 29, 17], 191, 'trainlm', QD, P, 4837);\n\n% Visualization\nprocessDataAndVisualize(QH', D', QD', P', trainedNetQHD, trainedNetQDP, 'figures');\nIn this script, data is first loaded from various .mat files. The train_nn function is used to train neural networks on the flow rate and head data (QH) and diameter (D). The processDataAndVisualize function then generates visualizations to compare neural network predictions with actual data points.\n\n\n\n\nThe QHforDiameters.m script focuses on optimizing neural network hyperparameters for better performance prediction. It uses a genetic algorithm to find the optimal neural network architecture, ensuring accurate predictions for different impeller diameters.\n\n\n\nInitialization: Loading data and initializing variables.\nHyperparameter Optimization: Using a genetic algorithm to find the optimal neural network architecture.\nPerformance Evaluation: Assessing the neural network’s performance on the training and test datasets.\nVisualization: Plotting the predicted performance curves for different impeller diameters.\n\n\n\n\nThe following MATLAB code snippet from QHforDiameters.m illustrates the process of optimizing neural network hyperparameters and visualizing the results:\nclear; clc; clf;\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD  = [filtered_QHD_table.Diameter_mm]';\n\nQH_beps=[deleted_QHD_table.FlowRate_m3h,deleted_QHD_table.Head_m]';\nD_beps=[deleted_QHD_table.Diameter_mm]';\n\nQD = [filtered_QDP_table.FlowRate_m3h,filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\nQD_beps=[deleted_QDP_table.FlowRate_m3h,deleted_QDP_table.Diameter_mm]';\nP_beps=[deleted_QDP_table.Power_kW]';\n\n% User-specified random seed (optional)\nuserSeed = 4826;\n\n% Define a threshold for MSE to exit the loop early\nmseThreshold = 0.000199;\n\n% Initialize result matrix\nresult = [];\n\n% Find all distinct diameters in D\ndistinctDiameters = unique(D);\n\n% Weights for combining MSEs\nweightDiameter = 0.5;\nweightBeps = 0.5;\n\nfor dIdx = 1:length(distinctDiameters)\n    % Current diameter to remove\n    diameterToRemove = distinctDiameters(dIdx);\n    \n    % Find indices of the current diameter in D\n    indicesToRemove = find(D == diameterToRemove);\n    \n    % Store the removed data for later use\n    removedQH = QH(:, indicesToRemove);\n    removedD = D(indicesToRemove);\n    \n    % Remove rows from QH and D based on the indices\n    QH_temp = QH;\n    D_temp = D;\n    QH_temp(:, indicesToRemove) = [];\n    D_temp(:, indicesToRemove) = [];\n    \n    % Initialize bounds\n    lower_bounds = [2, 13, 13, 1, 1];\n    upper_bounds = [2, 300, 300, 2, 1];\n    \n    % Track the previous combined MSE to determine the improvement\n    prevCombinedMSE = inf;\n\n    for\n\n i = 1:20\n        [optimalHyperParamsH, finalMSEH, randomSeedH, bestTrainedNetH, error] = optimizeNNForTrimmingPumpImpeller([QH_temp(1,:); D_temp], QH_temp(2,:), userSeed+i, lower_bounds, upper_bounds);\n\n        % Store result for this iteration\n        result(i, :) = [i, optimalHyperParamsH, finalMSEH, randomSeedH, error(1), error(2), error(3)];\n\n        % Calculate MSE for the removed diameter\n        predictedH = bestTrainedNetH([removedQH(1, :); removedD])';\n        mseDiameter = mean((removedQH(2, :)' - predictedH).^2 / sum(removedQH(2, :)));\n        predictedH_beps = bestTrainedNetH([QH_beps(1,:); D_beps])';\n        mseQH_beps = mean((QH_beps(2,:)' - predictedH_beps).^2 / sum(QH_beps(2,:)));\n\n        fprintf('Diameter %d, Iteration %d, MSE_Dia: %.6f,  MSE_beps: %.6f \\n', diameterToRemove, i, mseDiameter, mseQH_beps);\n\n        % Combine the two MSEs into a single metric\n        combinedMSE = weightDiameter * mseDiameter + weightBeps * mseQH_beps;\n        \n        % Determine the change in combined MSE\n        deltaMSE = prevCombinedMSE - combinedMSE;\n        \n        % Adjust the bounds based on the improvement in combined MSE\n        if deltaMSE &gt; 0.01  % Significant improvement\n            adjustment = [0, 5, 15, 0, 0];\n        elseif deltaMSE &gt; 0.001  % Moderate improvement\n            adjustment = [0, 2, 10, 0, 0];\n        else  % Minor improvement\n            adjustment = [0, 1, 5, 0, 0];\n        end\n        \n        lower_bounds = max(lower_bounds, [2, optimalHyperParamsH(2), optimalHyperParamsH(3), 1, 1] - adjustment);\n        upper_bounds = min(upper_bounds, [2, optimalHyperParamsH(2), optimalHyperParamsH(3), 2, 1] + adjustment);\n        \n        % Update the previous combined MSE for the next iteration\n        prevCombinedMSE = combinedMSE;\n\n        % Define desired diameter values \n        desiredDiameters = distinctDiameters; \n\n        % Create a single figure for all plots\n        figure;\n        hold on;  % Keep plots on the same figure\n\n        % Plot the removed diameter data points\n        scatter(removedQH(1, :)', removedQH(2, :)', 'r', 'filled', 'DisplayName', sprintf('Removed Diameter: %dmm', diameterToRemove));\n        \n        Qt = linspace(0, 400, 200);\n\n        for diameterIndex = 1:length(desiredDiameters)\n            desiredDiameter = desiredDiameters(diameterIndex);\n            Dt = repmat(desiredDiameter, length(Qt), 1);\n            filteredQH = bestTrainedNetH([Qt; Dt'])';\n            legendLabel = strcat('Diameter: ', num2str(desiredDiameter), 'mm');\n            plot(Qt, filteredQH, 'DisplayName', legendLabel);\n            text(Qt(end), filteredQH(end), sprintf('%dmm', desiredDiameter), 'FontSize', 8, 'Color', 'black', 'BackgroundColor', 'white');\n        end\n\n        scatter(Qa', Ha', 'b', 'filled', 'DisplayName', 'Reference Points');\n        \n        xlabel('Q (m^3/h)');\n        ylabel('H (m)');\n        title(['(Q, H) slices with Diameters, Removed Diameter: ' num2str(diameterToRemove) 'mm']);\n        legend;  \n        hold off;\n\n        filename = sprintf('../loop_05/01/nn_diameter-%d_iteration_%d_%d-%d-%d-%d-%d_mseDia-%d_test-%d.png', diameterToRemove, i, optimalHyperParamsH(1), optimalHyperParamsH(2), optimalHyperParamsH(3), optimalHyperParamsH(4), optimalHyperParamsH(5), mseDiameter, error(3));\n        saveas(gcf, filename);\n\n        filename = sprintf('../loop_05/01/nn_diameter-%d_iteration_%d_%d-%d-%d-%d-%d_mseDia-%d_test-%d.mat', diameterToRemove, i, optimalHyperParamsH(1), optimalHyperParamsH(2), optimalHyperParamsH(3), optimalHyperParamsH(4), optimalHyperParamsH(5), mseDiameter, error(3));\n        save(filename, 'bestTrainedNetH');\n\n        close(gcf);\n\n        if (mseDiameter &lt; mseThreshold) && (error(3) &lt; 0.0199) && (mseQH_beps &lt; mseThreshold) {\n            fprintf('MSE for diameter %d is below the threshold. Exiting loop.\\n', diameterToRemove);\n            break;\n        }\n    end\nend\n\nwritematrix([[\"Iteration\", \"Hidden Layer 1 Size\", \"Hidden Layer 2 Size\", \"Max Epochs\", \"Training Function\", \"Activation Function\", \"Final MSE\", \"Random Seed\", \"Training Error\", \"Validation Error\", \"Test Error\"]; result], './01/results_loop.csv');\ndisp('./01/Results saved to results_loop.csv');\nIn this script, data is loaded and prepared for training. The genetic algorithm is utilized to optimize neural network hyperparameters, ensuring accurate predictions for different impeller diameters. The optimizeNNForTrimmingPumpImpeller function performs the optimization, while the main script iterates through various diameters, training and evaluating the neural network’s performance. The visualization step plots the predicted performance curves for different diameters, allowing for easy comparison and analysis.\n\n\n\n\n\n\nThis chapter has outlined the significance of impeller trimming in centrifugal pump operation, traditional methods for trimming, and the advantages of using AI, specifically neural networks, for predicting pump performance. The implementation details provided in MATLAB highlight the practical aspects of this approach, demonstrating its potential for optimizing pump performance efficiently and accurately. The use of constant-area scaling and advanced neural network architectures underscores the importance of combining theoretical understanding with computational techniques to achieve optimal results."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#introduction",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#introduction",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Centrifugal pumps are integral components in various industrial applications, ranging from water supply systems to chemical processing. Optimizing their performance is crucial for enhancing energy efficiency and reducing operational costs. One key optimization technique is impeller trimming, which involves reducing the diameter of a pump impeller to align the pump’s performance more closely with the system requirements. This chapter explores the concept of impeller trimming, its significance, traditional methods, and the advantages of employing Artificial Intelligence (AI) for performance prediction."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#the-concept-of-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#the-concept-of-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Impeller trimming is the process of mechanically reducing the diameter of the pump impeller. This adjustment directly influences the pump’s head and flow rate, thereby modifying its performance characteristics. Trimming is performed to ensure that the pump operates within the desired performance range, avoiding over-delivery or under-delivery of fluid.\n\n\n\nImpeller trimming is essential for several reasons: 1. Energy Consumption: Proper trimming ensures that the pump operates at its optimal efficiency point, significantly reducing energy consumption. Each kilowatt saved at the pump level translates to approximately six kilowatts saved at the power station. 2. Market Availability: Pumps available in the market may not always fit specific system requirements precisely. Trimming provides a means to tailor the pump’s performance to meet these specific needs."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#energy-savings-and-environmental-impact",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#energy-savings-and-environmental-impact",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Impeller trimming is not only beneficial for energy savings but also contributes to environmental sustainability. Reduced energy consumption leads to lower greenhouse gas emissions. For every kilowatt-hour (kWh) saved by the pump, the reduction in power station output significantly decreases pollution, making trimming an environmentally responsible practice."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#traditional-methods-of-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#traditional-methods-of-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Instead of relying solely on empirical formulas and performance curves derived from extensive testing, scaling methods provide a mathematical approach to predicting the performance of a trimmed impeller. One such method is constant-area scaling, which assumes that the trimmed impeller maintains a constant area, ensuring proportional changes in flow and head.\n\n\nConstant-area scaling involves adjusting the impeller diameter while maintaining the proportional relationship between the flow rate and head. This method ensures that the trimmed impeller operates efficiently within the desired performance range, without significant deviations from the original design.\nThe constant-area scaling method is defined by the following relationship:\n[ D_{trimmed} = D_{original} ()^{1/2} ]\nWhere: - ( D_{trimmed} ) is the diameter of the trimmed impeller. - ( D_{original} ) is the original diameter of the impeller. - ( Q_{trimmed} ) is the desired flow rate after trimming. - ( Q_{original} ) is the original flow rate."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#artificial-neural-networks-for-impeller-trimming",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#artificial-neural-networks-for-impeller-trimming",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Artificial Neural Networks (ANNs) offer a robust alternative to traditional methods by leveraging large datasets to predict pump performance accurately. Unlike empirical methods, ANNs can model complex, non-linear relationships between variables, providing more precise predictions.\n\n\n\nAccuracy: ANNs can learn from vast amounts of data, capturing intricate patterns and relationships that traditional methods might miss.\nEfficiency: Once trained, ANNs can quickly predict performance outcomes for different impeller diameters, saving time and resources.\nAdaptability: Neural networks can be updated with new data, continuously improving their predictive capabilities.\n\n\n\n\nThe implementation of AI for impeller trimming was carried out using MATLAB. The scripts main_04.m and QHforDiameters.m are critical components of this implementation, leveraging optimized neural network architectures to predict pump performance based on different impeller diameters.\n\n\nThe main_04.m script incorporates the following key steps:\n\nData Loading: Loading datasets containing flow rate, head, diameter, and power metrics.\nNetwork Training: Training neural networks with optimized architectures to predict head and power based on flow rate and diameter.\nPerformance Evaluation: Evaluating the trained networks on various performance metrics to ensure accuracy and reliability.\nVisualization: Generating 3D plots to visualize the relationship between flow rate, head, diameter, and power, showcasing the neural network predictions versus actual data.\n\n\n\n\ntrain_nn: This function trains the neural network using the provided data, returning the trained model and performance metrics.\ntrim_diameters: This function determines the optimal trimmed diameter based on the provided pump data and performance criteria.\nprocessDataAndVisualize: This function processes the data and generates visualizations to compare neural network predictions with actual data points.\n\n\n\n\nThe following MATLAB code snippet from main_04.m demonstrates how to load data, train neural networks, and visualize the results:\nclear; clc; clf; close all;\n\n% Load data\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\n% Extract data\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD = [filtered_QHD_table.Diameter_mm]';\nQD = [filtered_QDP_table.FlowRate_m3h, filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\n% Train on full dataset\n[trainedNetQHD, ~, ~, ~, ~] = train_nn([2, 16], 191, 'trainlm', QH, D, 4837);\n[trainedNetQDP, ~, ~, ~, ~] = train_nn([2, 7, 29, 17], 191, 'trainlm', QD, P, 4837);\n\n% Visualization\nprocessDataAndVisualize(QH', D', QD', P', trainedNetQHD, trainedNetQDP, 'figures');\nIn this script, data is first loaded from various .mat files. The train_nn function is used to train neural networks on the flow rate and head data (QH) and diameter (D). The processDataAndVisualize function then generates visualizations to compare neural network predictions with actual data points.\n\n\n\n\nThe QHforDiameters.m script focuses on optimizing neural network hyperparameters for better performance prediction. It uses a genetic algorithm to find the optimal neural network architecture, ensuring accurate predictions for different impeller diameters.\n\n\n\nInitialization: Loading data and initializing variables.\nHyperparameter Optimization: Using a genetic algorithm to find the optimal neural network architecture.\nPerformance Evaluation: Assessing the neural network’s performance on the training and test datasets.\nVisualization: Plotting the predicted performance curves for different impeller diameters.\n\n\n\n\nThe following MATLAB code snippet from QHforDiameters.m illustrates the process of optimizing neural network hyperparameters and visualizing the results:\nclear; clc; clf;\nload('filtered_QHD_table.mat');\nload('filtered_QDP_table.mat');\nload('deleted_QHD_table.mat');\nload('deleted_QDP_table.mat');\n\nQH = [filtered_QHD_table.FlowRate_m3h, filtered_QHD_table.Head_m]';\nD  = [filtered_QHD_table.Diameter_mm]';\n\nQH_beps=[deleted_QHD_table.FlowRate_m3h,deleted_QHD_table.Head_m]';\nD_beps=[deleted_QHD_table.Diameter_mm]';\n\nQD = [filtered_QDP_table.FlowRate_m3h,filtered_QDP_table.Diameter_mm]';\nP = [filtered_QDP_table.Power_kW]';\n\nQD_beps=[deleted_QDP_table.FlowRate_m3h,deleted_QDP_table.Diameter_mm]';\nP_beps=[deleted_QDP_table.Power_kW]';\n\n% User-specified random seed (optional)\nuserSeed = 4826;\n\n% Define a threshold for MSE to exit the loop early\nmseThreshold = 0.000199;\n\n% Initialize result matrix\nresult = [];\n\n% Find all distinct diameters in D\ndistinctDiameters = unique(D);\n\n% Weights for combining MSEs\nweightDiameter = 0.5;\nweightBeps = 0.5;\n\nfor dIdx = 1:length(distinctDiameters)\n    % Current diameter to remove\n    diameterToRemove = distinctDiameters(dIdx);\n    \n    % Find indices of the current diameter in D\n    indicesToRemove = find(D == diameterToRemove);\n    \n    % Store the removed data for later use\n    removedQH = QH(:, indicesToRemove);\n    removedD = D(indicesToRemove);\n    \n    % Remove rows from QH and D based on the indices\n    QH_temp = QH;\n    D_temp = D;\n    QH_temp(:, indicesToRemove) = [];\n    D_temp(:, indicesToRemove) = [];\n    \n    % Initialize bounds\n    lower_bounds = [2, 13, 13, 1, 1];\n    upper_bounds = [2, 300, 300, 2, 1];\n    \n    % Track the previous combined MSE to determine the improvement\n    prevCombinedMSE = inf;\n\n    for\n\n i = 1:20\n        [optimalHyperParamsH, finalMSEH, randomSeedH, bestTrainedNetH, error] = optimizeNNForTrimmingPumpImpeller([QH_temp(1,:); D_temp], QH_temp(2,:), userSeed+i, lower_bounds, upper_bounds);\n\n        % Store result for this iteration\n        result(i, :) = [i, optimalHyperParamsH, finalMSEH, randomSeedH, error(1), error(2), error(3)];\n\n        % Calculate MSE for the removed diameter\n        predictedH = bestTrainedNetH([removedQH(1, :); removedD])';\n        mseDiameter = mean((removedQH(2, :)' - predictedH).^2 / sum(removedQH(2, :)));\n        predictedH_beps = bestTrainedNetH([QH_beps(1,:); D_beps])';\n        mseQH_beps = mean((QH_beps(2,:)' - predictedH_beps).^2 / sum(QH_beps(2,:)));\n\n        fprintf('Diameter %d, Iteration %d, MSE_Dia: %.6f,  MSE_beps: %.6f \\n', diameterToRemove, i, mseDiameter, mseQH_beps);\n\n        % Combine the two MSEs into a single metric\n        combinedMSE = weightDiameter * mseDiameter + weightBeps * mseQH_beps;\n        \n        % Determine the change in combined MSE\n        deltaMSE = prevCombinedMSE - combinedMSE;\n        \n        % Adjust the bounds based on the improvement in combined MSE\n        if deltaMSE &gt; 0.01  % Significant improvement\n            adjustment = [0, 5, 15, 0, 0];\n        elseif deltaMSE &gt; 0.001  % Moderate improvement\n            adjustment = [0, 2, 10, 0, 0];\n        else  % Minor improvement\n            adjustment = [0, 1, 5, 0, 0];\n        end\n        \n        lower_bounds = max(lower_bounds, [2, optimalHyperParamsH(2), optimalHyperParamsH(3), 1, 1] - adjustment);\n        upper_bounds = min(upper_bounds, [2, optimalHyperParamsH(2), optimalHyperParamsH(3), 2, 1] + adjustment);\n        \n        % Update the previous combined MSE for the next iteration\n        prevCombinedMSE = combinedMSE;\n\n        % Define desired diameter values \n        desiredDiameters = distinctDiameters; \n\n        % Create a single figure for all plots\n        figure;\n        hold on;  % Keep plots on the same figure\n\n        % Plot the removed diameter data points\n        scatter(removedQH(1, :)', removedQH(2, :)', 'r', 'filled', 'DisplayName', sprintf('Removed Diameter: %dmm', diameterToRemove));\n        \n        Qt = linspace(0, 400, 200);\n\n        for diameterIndex = 1:length(desiredDiameters)\n            desiredDiameter = desiredDiameters(diameterIndex);\n            Dt = repmat(desiredDiameter, length(Qt), 1);\n            filteredQH = bestTrainedNetH([Qt; Dt'])';\n            legendLabel = strcat('Diameter: ', num2str(desiredDiameter), 'mm');\n            plot(Qt, filteredQH, 'DisplayName', legendLabel);\n            text(Qt(end), filteredQH(end), sprintf('%dmm', desiredDiameter), 'FontSize', 8, 'Color', 'black', 'BackgroundColor', 'white');\n        end\n\n        scatter(Qa', Ha', 'b', 'filled', 'DisplayName', 'Reference Points');\n        \n        xlabel('Q (m^3/h)');\n        ylabel('H (m)');\n        title(['(Q, H) slices with Diameters, Removed Diameter: ' num2str(diameterToRemove) 'mm']);\n        legend;  \n        hold off;\n\n        filename = sprintf('../loop_05/01/nn_diameter-%d_iteration_%d_%d-%d-%d-%d-%d_mseDia-%d_test-%d.png', diameterToRemove, i, optimalHyperParamsH(1), optimalHyperParamsH(2), optimalHyperParamsH(3), optimalHyperParamsH(4), optimalHyperParamsH(5), mseDiameter, error(3));\n        saveas(gcf, filename);\n\n        filename = sprintf('../loop_05/01/nn_diameter-%d_iteration_%d_%d-%d-%d-%d-%d_mseDia-%d_test-%d.mat', diameterToRemove, i, optimalHyperParamsH(1), optimalHyperParamsH(2), optimalHyperParamsH(3), optimalHyperParamsH(4), optimalHyperParamsH(5), mseDiameter, error(3));\n        save(filename, 'bestTrainedNetH');\n\n        close(gcf);\n\n        if (mseDiameter &lt; mseThreshold) && (error(3) &lt; 0.0199) && (mseQH_beps &lt; mseThreshold) {\n            fprintf('MSE for diameter %d is below the threshold. Exiting loop.\\n', diameterToRemove);\n            break;\n        }\n    end\nend\n\nwritematrix([[\"Iteration\", \"Hidden Layer 1 Size\", \"Hidden Layer 2 Size\", \"Max Epochs\", \"Training Function\", \"Activation Function\", \"Final MSE\", \"Random Seed\", \"Training Error\", \"Validation Error\", \"Test Error\"]; result], './01/results_loop.csv');\ndisp('./01/Results saved to results_loop.csv');\nIn this script, data is loaded and prepared for training. The genetic algorithm is utilized to optimize neural network hyperparameters, ensuring accurate predictions for different impeller diameters. The optimizeNNForTrimmingPumpImpeller function performs the optimization, while the main script iterates through various diameters, training and evaluating the neural network’s performance. The visualization step plots the predicted performance curves for different diameters, allowing for easy comparison and analysis."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#conclusion",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/index_01.html#conclusion",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "This chapter has outlined the significance of impeller trimming in centrifugal pump operation, traditional methods for trimming, and the advantages of using AI, specifically neural networks, for predicting pump performance. The implementation details provided in MATLAB highlight the practical aspects of this approach, demonstrating its potential for optimizing pump performance efficiently and accurately. The use of constant-area scaling and advanced neural network architectures underscores the importance of combining theoretical understanding with computational techniques to achieve optimal results."
  },
  {
    "objectID": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/gallery.html",
    "href": "data/writings/posts/2024-06-24-chapter-1-trimming -AI/gallery.html",
    "title": "Application of Artificial Intelligence on the Centrifugal Pump Operation",
    "section": "",
    "text": "Figures\n\nGallery of Figures\n\n\n\n  \n    \n      \n        best_nn_diameter_power_visualization_2024-06-26_23-49-25\n        \n        Description of best_nn_diameter_power_visualization_2024-06-26_23-49-25\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        best_nn_diameter_power_visualization_2024-06-27_05-02-57\n        \n        Description of best_nn_diameter_power_visualization_2024-06-27_05-02-57\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_10_2-51-264-1-1_mseDia-4.631136e-03_test-1.474209e-03\n        \n        Description of nn_diameter-220_iteration_10_2-51-264-1-1_mseDia-4.631136e-03_test-1.474209e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_11_2-52-261-1-1_mseDia-3.540134e-02_test-5.639226e-03\n        \n        Description of nn_diameter-220_iteration_11_2-52-261-1-1_mseDia-3.540134e-02_test-5.639226e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_12_2-51-262-1-1_mseDia-6.829475e-03_test-4.445475e-03\n        \n        Description of nn_diameter-220_iteration_12_2-51-262-1-1_mseDia-6.829475e-03_test-4.445475e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_13_2-52-264-1-1_mseDia-4.526453e-04_test-6.299822e-03\n        \n        Description of nn_diameter-220_iteration_13_2-52-264-1-1_mseDia-4.526453e-04_test-6.299822e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_14_2-51-259-1-1_mseDia-2.193948e-03_test-2.819540e-03\n        \n        Description of nn_diameter-220_iteration_14_2-51-259-1-1_mseDia-2.193948e-03_test-2.819540e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_15_2-52-264-1-1_mseDia-1.869470e-02_test-1.080346e-03\n        \n        Description of nn_diameter-220_iteration_15_2-52-264-1-1_mseDia-1.869470e-02_test-1.080346e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_16_2-51-264-1-1_mseDia-2.089594e-03_test-3.406835e-03\n        \n        Description of nn_diameter-220_iteration_16_2-51-264-1-1_mseDia-2.089594e-03_test-3.406835e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_17_2-51-263-1-1_mseDia-6.729495e-02_test-9.282804e+00\n        \n        Description of nn_diameter-220_iteration_17_2-51-263-1-1_mseDia-6.729495e-02_test-9.282804e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_18_2-52-260-1-1_mseDia-5.216853e-03_test-1.034067e+00\n        \n        Description of nn_diameter-220_iteration_18_2-52-260-1-1_mseDia-5.216853e-03_test-1.034067e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_19_2-51-262-1-1_mseDia-4.303755e-04_test-5.570226e-02\n        \n        Description of nn_diameter-220_iteration_19_2-51-262-1-1_mseDia-4.303755e-04_test-5.570226e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_1_2-48-255-1-1_mseDia-1.451433e-04_test-1.443107e-02\n        \n        Description of nn_diameter-220_iteration_1_2-48-255-1-1_mseDia-1.451433e-04_test-1.443107e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_20_2-52-262-1-1_mseDia-7.448321e-03_test-9.132916e-04\n        \n        Description of nn_diameter-220_iteration_20_2-52-262-1-1_mseDia-7.448321e-03_test-9.132916e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_2_2-51-261-1-1_mseDia-7.942964e-01_test-2.495736e-02\n        \n        Description of nn_diameter-220_iteration_2_2-51-261-1-1_mseDia-7.942964e-01_test-2.495736e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_3_2-50-262-1-1_mseDia-1.662826e-01_test-8.739276e+00\n        \n        Description of nn_diameter-220_iteration_3_2-50-262-1-1_mseDia-1.662826e-01_test-8.739276e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_4_2-50-263-1-1_mseDia-5.526657e-03_test-2.431055e+00\n        \n        Description of nn_diameter-220_iteration_4_2-50-263-1-1_mseDia-5.526657e-03_test-2.431055e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_5_2-52-261-1-1_mseDia-5.826613e-02_test-2.183893e-01\n        \n        Description of nn_diameter-220_iteration_5_2-52-261-1-1_mseDia-5.826613e-02_test-2.183893e-01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_6_2-51-264-1-1_mseDia-1.620744e-01_test-7.017350e-04\n        \n        Description of nn_diameter-220_iteration_6_2-51-264-1-1_mseDia-1.620744e-01_test-7.017350e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_7_2-51-259-1-1_mseDia-3.427594e-04_test-1.807621e-01\n        \n        Description of nn_diameter-220_iteration_7_2-51-259-1-1_mseDia-3.427594e-04_test-1.807621e-01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_8_2-52-263-1-1_mseDia-1.049658e-03_test-9.818476e-02\n        \n        Description of nn_diameter-220_iteration_8_2-52-263-1-1_mseDia-1.049658e-03_test-9.818476e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-220_iteration_9_2-52-262-1-1_mseDia-5.042946e-01_test-4.279715e+00\n        \n        Description of nn_diameter-220_iteration_9_2-52-262-1-1_mseDia-5.042946e-01_test-4.279715e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_10_2-16-192-1-1_mseDia-6.539777e-06_test-4.418643e-02\n        \n        Description of nn_diameter-230_iteration_10_2-16-192-1-1_mseDia-6.539777e-06_test-4.418643e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_11_2-16-191-1-1_mseDia-1.897601e-04_test-8.967212e-03\n        \n        Description of nn_diameter-230_iteration_11_2-16-191-1-1_mseDia-1.897601e-04_test-8.967212e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_1_2-14-189-1-1_mseDia-2.123792e-04_test-2.682739e+00\n        \n        Description of nn_diameter-230_iteration_1_2-14-189-1-1_mseDia-2.123792e-04_test-2.682739e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_2_2-15-191-1-1_mseDia-4.573431e-04_test-3.076450e-02\n        \n        Description of nn_diameter-230_iteration_2_2-15-191-1-1_mseDia-4.573431e-04_test-3.076450e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_3_2-16-191-1-1_mseDia-2.098153e-05_test-1.996420e-01\n        \n        Description of nn_diameter-230_iteration_3_2-16-191-1-1_mseDia-2.098153e-05_test-1.996420e-01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_4_2-16-193-1-1_mseDia-2.922957e-05_test-1.140381e-01\n        \n        Description of nn_diameter-230_iteration_4_2-16-193-1-1_mseDia-2.922957e-05_test-1.140381e-01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_5_2-16-194-1-1_mseDia-2.667331e-05_test-3.306433e-01\n        \n        Description of nn_diameter-230_iteration_5_2-16-194-1-1_mseDia-2.667331e-05_test-3.306433e-01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_6_2-15-195-1-1_mseDia-7.611546e-03_test-7.003550e+00\n        \n        Description of nn_diameter-230_iteration_6_2-15-195-1-1_mseDia-7.611546e-03_test-7.003550e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_7_2-15-195-1-1_mseDia-2.203415e-02_test-2.568556e-02\n        \n        Description of nn_diameter-230_iteration_7_2-15-195-1-1_mseDia-2.203415e-02_test-2.568556e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_8_2-16-194-1-1_mseDia-2.878154e-05_test-4.467712e-02\n        \n        Description of nn_diameter-230_iteration_8_2-16-194-1-1_mseDia-2.878154e-05_test-4.467712e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-230_iteration_9_2-15-190-1-1_mseDia-1.608663e-05_test-2.695317e-02\n        \n        Description of nn_diameter-230_iteration_9_2-15-190-1-1_mseDia-1.608663e-05_test-2.695317e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-240_iteration_1_2-40-264-1-1_mseDia-1.552556e-06_test-2.915896e-01\n        \n        Description of nn_diameter-240_iteration_1_2-40-264-1-1_mseDia-1.552556e-06_test-2.915896e-01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-240_iteration_2_2-40-250-1-1_mseDia-1.717564e-04_test-2.364596e-03\n        \n        Description of nn_diameter-240_iteration_2_2-40-250-1-1_mseDia-1.717564e-04_test-2.364596e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-240_iteration_3_2-40-251-1-1_mseDia-1.426877e-03_test-2.078074e-03\n        \n        Description of nn_diameter-240_iteration_3_2-40-251-1-1_mseDia-1.426877e-03_test-2.078074e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-240_iteration_4_2-39-249-1-1_mseDia-6.810560e-05_test-1.279386e-03\n        \n        Description of nn_diameter-240_iteration_4_2-39-249-1-1_mseDia-6.810560e-05_test-1.279386e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_10_2-43-254-1-1_mseDia-8.299140e-03_test-7.474668e+00\n        \n        Description of nn_diameter-250_iteration_10_2-43-254-1-1_mseDia-8.299140e-03_test-7.474668e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_11_2-43-255-1-1_mseDia-2.468579e-01_test-3.724990e+01\n        \n        Description of nn_diameter-250_iteration_11_2-43-255-1-1_mseDia-2.468579e-01_test-3.724990e+01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_12_2-43-252-1-1_mseDia-1.497363e-03_test-8.321293e-04\n        \n        Description of nn_diameter-250_iteration_12_2-43-252-1-1_mseDia-1.497363e-03_test-8.321293e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_13_2-43-252-1-1_mseDia-5.627291e-04_test-3.175057e-02\n        \n        Description of nn_diameter-250_iteration_13_2-43-252-1-1_mseDia-5.627291e-04_test-3.175057e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_14_2-43-250-1-1_mseDia-2.920388e-04_test-4.679399e-03\n        \n        Description of nn_diameter-250_iteration_14_2-43-250-1-1_mseDia-2.920388e-04_test-4.679399e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_15_2-44-255-1-1_mseDia-1.510201e-02_test-1.263276e-03\n        \n        Description of nn_diameter-250_iteration_15_2-44-255-1-1_mseDia-1.510201e-02_test-1.263276e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_16_2-43-250-1-1_mseDia-6.112923e-05_test-2.322065e-03\n        \n        Description of nn_diameter-250_iteration_16_2-43-250-1-1_mseDia-6.112923e-05_test-2.322065e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_1_2-40-254-1-1_mseDia-2.762442e-04_test-1.058931e-02\n        \n        Description of nn_diameter-250_iteration_1_2-40-254-1-1_mseDia-2.762442e-04_test-1.058931e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_2_2-44-255-1-1_mseDia-4.458115e-03_test-3.020039e-02\n        \n        Description of nn_diameter-250_iteration_2_2-44-255-1-1_mseDia-4.458115e-03_test-3.020039e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_3_2-43-250-1-1_mseDia-2.587186e-03_test-9.379359e-04\n        \n        Description of nn_diameter-250_iteration_3_2-43-250-1-1_mseDia-2.587186e-03_test-9.379359e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_4_2-44-253-1-1_mseDia-4.812756e-02_test-2.261070e-03\n        \n        Description of nn_diameter-250_iteration_4_2-44-253-1-1_mseDia-4.812756e-02_test-2.261070e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_5_2-43-250-1-1_mseDia-3.731435e-03_test-1.737575e-03\n        \n        Description of nn_diameter-250_iteration_5_2-43-250-1-1_mseDia-3.731435e-03_test-1.737575e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_6_2-44-253-1-1_mseDia-1.436546e-04_test-1.130975e-03\n        \n        Description of nn_diameter-250_iteration_6_2-44-253-1-1_mseDia-1.436546e-04_test-1.130975e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_7_2-44-254-1-1_mseDia-9.584743e-03_test-2.373867e-01\n        \n        Description of nn_diameter-250_iteration_7_2-44-254-1-1_mseDia-9.584743e-03_test-2.373867e-01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_8_2-43-253-1-1_mseDia-4.389759e-03_test-3.646521e+00\n        \n        Description of nn_diameter-250_iteration_8_2-43-253-1-1_mseDia-4.389759e-03_test-3.646521e+00\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-250_iteration_9_2-43-250-1-1_mseDia-6.934819e-04_test-1.905809e-03\n        \n        Description of nn_diameter-250_iteration_9_2-43-250-1-1_mseDia-6.934819e-04_test-1.905809e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_10_2-50-242-1-1_mseDia-5.610540e+00_test-1.390688e-02\n        \n        Description of nn_diameter-260_iteration_10_2-50-242-1-1_mseDia-5.610540e+00_test-1.390688e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_11_2-49-240-1-1_mseDia-3.939663e-03_test-1.532100e-03\n        \n        Description of nn_diameter-260_iteration_11_2-49-240-1-1_mseDia-3.939663e-03_test-1.532100e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_12_2-50-245-1-1_mseDia-5.483495e-03_test-1.260306e-03\n        \n        Description of nn_diameter-260_iteration_12_2-50-245-1-1_mseDia-5.483495e-03_test-1.260306e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_13_2-49-242-1-1_mseDia-2.719966e-03_test-1.262362e-03\n        \n        Description of nn_diameter-260_iteration_13_2-49-242-1-1_mseDia-2.719966e-03_test-1.262362e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_14_2-49-240-1-1_mseDia-1.135403e-02_test-1.048174e-03\n        \n        Description of nn_diameter-260_iteration_14_2-49-240-1-1_mseDia-1.135403e-02_test-1.048174e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_15_2-50-245-1-1_mseDia-1.914322e-02_test-8.892275e-04\n        \n        Description of nn_diameter-260_iteration_15_2-50-245-1-1_mseDia-1.914322e-02_test-8.892275e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_16_2-49-240-1-1_mseDia-2.427548e-03_test-9.909529e-04\n        \n        Description of nn_diameter-260_iteration_16_2-49-240-1-1_mseDia-2.427548e-03_test-9.909529e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_17_2-49-240-1-1_mseDia-8.289200e-02_test-9.554322e-03\n        \n        Description of nn_diameter-260_iteration_17_2-49-240-1-1_mseDia-8.289200e-02_test-9.554322e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_18_2-50-245-1-1_mseDia-4.468881e-03_test-1.010439e-02\n        \n        Description of nn_diameter-260_iteration_18_2-50-245-1-1_mseDia-4.468881e-03_test-1.010439e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_19_2-49-243-1-1_mseDia-3.609624e-03_test-3.850919e-02\n        \n        Description of nn_diameter-260_iteration_19_2-49-243-1-1_mseDia-3.609624e-03_test-3.850919e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_1_2-49-255-1-1_mseDia-4.136578e-03_test-1.113098e-02\n        \n        Description of nn_diameter-260_iteration_1_2-49-255-1-1_mseDia-4.136578e-03_test-1.113098e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_20_2-50-243-1-1_mseDia-3.500926e-02_test-7.055046e-04\n        \n        Description of nn_diameter-260_iteration_20_2-50-243-1-1_mseDia-3.500926e-02_test-7.055046e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_2_2-49-241-1-1_mseDia-6.520750e-03_test-9.190240e-04\n        \n        Description of nn_diameter-260_iteration_2_2-49-241-1-1_mseDia-6.520750e-03_test-9.190240e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_3_2-49-242-1-1_mseDia-5.176642e-03_test-8.972362e-04\n        \n        Description of nn_diameter-260_iteration_3_2-49-242-1-1_mseDia-5.176642e-03_test-8.972362e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_4_2-49-240-1-1_mseDia-3.486987e-03_test-1.148965e-02\n        \n        Description of nn_diameter-260_iteration_4_2-49-240-1-1_mseDia-3.486987e-03_test-1.148965e-02\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_5_2-49-244-1-1_mseDia-4.711585e-02_test-2.015901e-03\n        \n        Description of nn_diameter-260_iteration_5_2-49-244-1-1_mseDia-4.711585e-02_test-2.015901e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_6_2-48-240-1-1_mseDia-3.580358e-03_test-1.035566e-03\n        \n        Description of nn_diameter-260_iteration_6_2-48-240-1-1_mseDia-3.580358e-03_test-1.035566e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_7_2-50-242-1-1_mseDia-5.120050e-03_test-4.864993e-03\n        \n        Description of nn_diameter-260_iteration_7_2-50-242-1-1_mseDia-5.120050e-03_test-4.864993e-03\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_8_2-49-244-1-1_mseDia-2.680748e+01_test-4.151179e-01\n        \n        Description of nn_diameter-260_iteration_8_2-49-244-1-1_mseDia-2.680748e+01_test-4.151179e-01\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        nn_diameter-260_iteration_9_2-49-240-1-1_mseDia-5.274027e-01_test-9.101108e-04\n        \n        Description of nn_diameter-260_iteration_9_2-49-240-1-1_mseDia-5.274027e-01_test-9.101108e-04\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDH_Diameter_220\n        \n        Description of QDH_Diameter_220\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDH_Diameter_230\n        \n        Description of QDH_Diameter_230\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDH_Diameter_240\n        \n        Description of QDH_Diameter_240\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDH_Diameter_250\n        \n        Description of QDH_Diameter_250\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDH_Diameter_260\n        \n        Description of QDH_Diameter_260\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDP_Diameter_220\n        \n        Description of QDP_Diameter_220\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDP_Diameter_230\n        \n        Description of QDP_Diameter_230\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDP_Diameter_240\n        \n        Description of QDP_Diameter_240\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDP_Diameter_250\n        \n        Description of QDP_Diameter_250\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QDP_Diameter_260\n        \n        Description of QDP_Diameter_260\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QHD_Diameter_220\n        \n        Description of QHD_Diameter_220\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QHD_Diameter_230\n        \n        Description of QHD_Diameter_230\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QHD_Diameter_240\n        \n        Description of QHD_Diameter_240\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QHD_Diameter_250\n        \n        Description of QHD_Diameter_250\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        QHD_Diameter_260\n        \n        Description of QHD_Diameter_260\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        Q_eta_curves_with_BEPs\n        \n        Description of Q_eta_curves_with_BEPs\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        Q_eta_mtk_curves_with_BEPs\n        \n        Description of Q_eta_mtk_curves_with_BEPs\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        Q_H_curves_with_BEPs\n        \n        Description of Q_H_curves_with_BEPs\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        Q_H_mtk_curves_with_BEPs\n        \n        Description of Q_H_mtk_curves_with_BEPs\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        Q_P_curves_with_BEPs\n        \n        Description of Q_P_curves_with_BEPs\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n  \n    \n      \n        Q_P_mtk_curves_with_BEPs\n        \n        Description of Q_P_mtk_curves_with_BEPs\n      \n    \n    \n      \n    \n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data/writings/posts/trimming_15-4-2024/index.html",
    "href": "data/writings/posts/trimming_15-4-2024/index.html",
    "title": "Beyond Trial and Error: A Machine Learning Approach to Optimal Centrifugal Pump Impeller Trimming",
    "section": "",
    "text": "MS WordPDF (elsevier)"
  },
  {
    "objectID": "data/writings/posts/trimming_15-4-2024/index.html#methodology",
    "href": "data/writings/posts/trimming_15-4-2024/index.html#methodology",
    "title": "Beyond Trial and Error: A Machine Learning Approach to Optimal Centrifugal Pump Impeller Trimming",
    "section": "Methodology",
    "text": "Methodology\nThis section outlines the methodology employed to optimize the hyperparameters of an artificial neural network (NN) for predicting pump impeller diameter (D) in the context of impeller trimming. The optimization process utilizes a genetic algorithm (GA) implemented using the MATLAB GA toolbox.\nData Acquisition and Preprocessing:\nThe methodology leverages a dataset containing impeller geometries and their corresponding performance data, including flow rate (Q), head (H), diameter (D), and pump power (P). While the dataset doesn’t include a direct measurement of efficiency (\\(\\eta\\)), it can be calculated using the provided information and the following equation:\n\\[\nP = \\frac{Q*\\rho*g*H}{\\eta}\n\\]\nwhere:\n\n\\(\\eta\\) is the pump efficiency (-)\n\\(\\rho\\) is the fluid density \\((kg/m^3)\\)\n\\(g\\) is the acceleration due to gravity \\((m/s^2)\\)\n\nThis data can be obtained from various sources, such as experimental measurements, computational fluid dynamics (CFD) simulations, or a combination of both. Our code (refer to the provided MATLAB code for specific details)1 performs the following data preprocessing steps:\n\nData Cleaning: The data is inspected for missing values or outliers. Missing values can be addressed through techniques like imputation or deletion, while outliers may require further investigation or removal if they significantly impact the training process.\nNormalization: The data is normalized to a specific range (often -1 to 1 or 0 to 1) using techniques like mapminmax in MATLAB. This helps ensure the gradients calculated during backpropagation have a more consistent magnitude, facilitating faster convergence and avoiding local minima during training.\n\nNeural Network Architecture:\nThe proposed NN architecture utilizes a supervised learning approach for regression. The specific details in the code will determine the exact structure, but a typical configuration might involve:\n\nInput Layer: This layer consists of two neurons, corresponding to the input features: flow rate (Q) and head (H).\nHidden Layer(s): One or more hidden layers are employed to learn complex relationships between the input and output data. The GA will optimize the number of neurons in the hidden layer(s) based on performance.\nOutput Layer: The output layer contains a single neuron responsible for predicting the impeller diameter (D).\n\nThe activation functions used in each layer will also be optimized by the GA. The code specifically uses two common choices for activation functions in regression tasks:\n\nSigmoid (Logistic Function): This function takes the form f(x) = 1 / (1 + exp(-x)). It squashes the input values between 0 and 1, introducing non-linearity into the network. Mathematically, the sigmoid function can be expressed as: \\[\nf(x) = \\frac{1}{1 + e^{-x}}\n\\]\nTanh (Hyperbolic Tangent Function): This function takes the form f(x) = (tanh(x)) = (e^x - e^{-x}) / (e^x + e^{-x}). It squashes the input values between -1 and 1, providing a wider range of output compared to the sigmoid function. Mathematically, the tanh function can be expressed as: \\[\nf(x) = \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n\\]\n\nBoth sigmoid and tansig (which is mathematically equivalent to tanh) functions introduce non-linearity into the network, allowing it to model complex relationships between the input and output data. The GA will evaluate the performance of the NN using different activation functions (sigmoid and tansig) and select the one that leads to the minimal MSE between predicted and actual data.\nThe tansig function used in your code is defined as: \\[\nf(x) = tansig(x) = \\frac{2}{1 + exp(-2x)} - 1\n\\]\nGenetic Algorithm (GA) for Hyperparameter Optimization:\nThe GA serves as the core optimization engine, searching for the optimal combination of NN hyperparameters that minimizes the mean squared error (MSE) between the network’s predicted diameter (D) and the actual values in the training data. and here is some glimpses on how in general it works:\n\nPopulation Initialization: The GA starts with a population of individuals (candidate hyperparameter sets). Each individual represents a unique configuration for the NN, including hidden layer size, training function, activation function, and maximum epochs.\nFitness Evaluation: Each individual in the population undergoes evaluation. The code trains an NN using the specific hyperparameters encoded in the individual’s chromosome. The resulting NN’s performance is then measured by calculating the MSE between its predicted diameter (D) and the actual values on a validation dataset (a portion of the original data set aside for evaluation).\nSelection: Based on the fitness values (MSE), the GA selects a subset of individuals with superior performance (low MSE) to become parents for the next generation.\nCrossover: Selected parent individuals undergo crossover, where portions of their genetic material (hyperparameter configurations) are exchanged to create new offspring (candidate solutions).\nMutation: A small probability of mutation is introduced to introduce random variations in the offspring’s chromosomes. This helps maintain genetic diversity and explore new regions of the search space.\nReplacement and Termination: The new generation of offspring replaces a portion of the lower-performing individuals in the population. The GA iterates through these steps until a stopping criterion is met, such as reaching a maximum number of generations or achieving a desired level of convergence (minimum MSE).\n\nThe code (refer to the MATLAB code for specific details) will implement the specific selection, crossover, and mutation operators used in the GA and all of this is handled by ga the MATLAB toolbox.\nTraining and Validation:\nThe final, selected hyperparameter configuration from the GA is used to train a new NN model. This model is trained on a separate training dataset, excluding the data used for validation during the GA optimization process. The trained model is then evaluated on a hold-out test dataset to assess its generalizability and prediction accuracy on unseen data.\nPerformance Evaluation:\nThe performance of the trained NN model is evaluated based on various metrics, including:\n\nMean Squared Error (MSE): This metric measures the average squared difference between the predicted impeller diameters (D) and the actual values in the test dataset. A lower MSE indicates better prediction accuracy.\nCoefficient of Determination (R-squared): This metric indicates the proportion of the variance in the actual diameter data explained by the NN model’s predictions. A value closer to 1 signifies a stronger correlation between the predicted and actual values.\nVisualization Techniques: Visualizations such as scatter plots comparing predicted vs. actual data."
  },
  {
    "objectID": "data/writings/posts/trimming_15-4-2024/index.html#footnotes",
    "href": "data/writings/posts/trimming_15-4-2024/index.html#footnotes",
    "title": "Beyond Trial and Error: A Machine Learning Approach to Optimal Centrifugal Pump Impeller Trimming",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ngithub link to our code:https://github.com/MohammedTwheed/trimming-code ↩︎\nwe will find the dataset we used at: https://github.com/MohammedTwheed/trimming-code/tree/main/training-data↩︎"
  },
  {
    "objectID": "data/writings/index.html",
    "href": "data/writings/index.html",
    "title": "AI Applications in Pumps",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nApplication of Artificial Intelligence on the Centrifugal Pump Operation\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nMohammed Twheed Khater\n\n\n\n\n\n\n\n\n\n\n\n\nExploartion_17 : Tree-Based Genetic Programming for Polynomial Regression\n\n\nthis is for matlab_translation_symbolic_regression_18.m file implementation\n\n\n\ngenetic-algorithms\n\n\nsymbolic-regression\n\n\nMATLAB\n\n\n\nThis document is intended to be a simpler alternative for translating symbolic regression code from Python to MATLAB. It focuses on a more straightforward approach, as translating the Node and Tree classes from the Python code on GitHub (by dyckia, titled “Genetic-Programming-Polynomial-Regression”) proved challenging.\na complete example working matlab file matlab_translation_symbolic_regression_18.m will be sent with this document via whatsapp.\nlater i will upload it to github with proper permenant link.\nhere is link the translated file : - matlab_translation_symbolic_regression_18.m\nhere is link to the training data used : - A4_trainingSamples.txt \n\n\n\n\n\nJun 23, 2024\n\n\nMohammed Tawheed Khater\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Trial and Error: A Machine Learning Approach to Optimal Centrifugal Pump Impeller Trimming\n\n\nA Genetic Algorithm Hyperparameter Optimization Approach\n\n\nThis paper proposes a genetic algorithm (GA)-based methodology to optimize hyperparameters for artificial neural networks (NNs) applied to pump impeller trimming. Traditionally, impeller trimming relies on expert knowledge and empirical methods, leading to time-consuming and potentially suboptimal outcomes. This work introduces a data-driven approach using NNs trained to predict the impeller diameter (D) and pump power (P), which can be calculated from flow rate (Q), density (\\(\\rho\\)), head (H), and efficiency (\\(\\eta\\)) using the equation P = (Q * \\(\\rho\\) * g * H) / \\(\\eta\\). based on the desired operating point (flow rate (Q) and head (H)). A GA is employed to identify the optimal NN hyperparameters, including hidden layer size, training function, activation function, and maximum epochs. The goal is to minimize the mean squared error (MSE) between the network’s predictions and the actual performance data. The paper details the implementation of the GA optimization process and discusses the key components and their significance in achieving optimal impeller trimming through NN predictions. \n\n\n\n\n\nApr 15, 2024\n\n\nMohamed Farid Khalil, Mohammed Twheed Khater, Seif Ibrahim Hassan\n\n\n\n\n\n\nNo matching items"
  }
]